'use strict';(function(){const indexCfg=;indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/00_Introduction/','title':"00 Introduction",'content':" Introduction What is this book? The core idea of this book is teaching Unity as a tool for creative people of all kinds. This is a “living” book. It means things will change, parts will grow, others will wither. This is for multiple reasons. For one, I am not an expert on all topics in Unity, I guess one can’t be. I have a background in Media-Design and am trying to learn and in this case teach Unity to the best of my ability. This means that if you find errors, tell me and I will try to fix them. Unity and its programming language C#, are living things. Unity releases new Versions three times a year, if you count in betas and package updates, then a lot of change is happening all the time. So best practices can change and I will do my best to maintain these changes in this book. As of now, all of this will be up-to-date with the Unity 2019.4 LTS (long-term support) version.\nIn the beginning of this book I will teach Unity and C# using “creative coding” or “Generative Design”. I will start with coding, because no matter what you want to do with it, the sooner you become familiar with the coding bits, the easier the rest of it will become. While Unity has many uses (see further down) most of them will require you to know aspects of the software. So while a simple game like “Block Breaker” or “Asteroids” may not be too hard to clone, you have to deal with several aspects when putting it all together. Think: User Input, Graphics, User Interface, Sound, etc.. While “Creative Coding” can get very complex, we can isolate ideas and try to be creative with them in isolation. This helps to build mileage and gives us the opportunity to take a step back and think about our visual output. With “Creative Coding” we will look at the things you would see from people learning or using Processing. While Processing is great and I encourage anyone to look into it, Unity gives us more possibilities. Processing relies on programming for creating output, we will make use of the added tools Unity provides. This can overwhelm in the beginning, yet I assure you that most of the tools simplify our lives.\nWho is this for? In this book I will assume that you have no knowledge of game engines, 3D or programming. If you do, try to start at a point that seems to be the end of your current knowledge. Working with game engines often requires you to have access to 3D models which are created in other software. I can’t go over showing you how to create them in this book, but will provide you all the models you need to follow the book. You can also find many, many models for free or for cheap in the Unity Asset store.\n### What is “Creative Coding”? Creative Coding is a somewhat weird term. As programming is problem solving, any coding requires creativity. Whether in the finance industries, industry automation, gaming or innovative Artificial intelligence projects. Yet “Creative Coding” is widely adopted as a term for artworks created through code. As mentioned before, we will stretch this term a little and will not only rely on code to create our works, but will also use the editor tools.\n“Processing”? Processing is the most influential programming Framework for creative coding. It has a very shallow learning curve and features many convenient shortcuts for creative coding while still maintaining the ability to create wonderful and complex artworks. With the addition of p5.js to the Processing family it is now running on a Javascript basis in the Web browser and is used to build lively and reactive websites. While Processing has capabilities to create 3D projects, Unity will outshine Processing in this area by a large margin.\n“Why Unity?” While Unity is not optimized for Creative Coding, and learning to code for Unity might be harder than learning \u0026ldquo;Processing”, most ideas are the same. And while Unity will introduce more “clutter” into the journey to programming it enables its users to do so much more. It includes a full-featured 3D Engine and even AI Tools. But even more: C# - The programming language used to code - is very, very versatile. With it you can write native applications for Windows, Linux and Mac and Apps for iOS or Android. I think Unity is a great place to learn to code for “creatives”.\n“But\u0026hellip; Unreal Engine?” Unreal Engine is a fantastic 3D render engine, and now more and more widely adapted in many industries, as is Unity. But programming in Unreal is hard, because the underlying language is “C++”. While there are many, many similarities between both languages, “C#” handles the more tedious and complex programming tasks for us. If you reach a point where you know C# well, switching to C++ won’t be that hard any more. Thus you won’t be making a mistake starting here. That said, if you know you want to become a programmer for absolute high-end experiences, and be part of a larger team I suggest looking straight at C++ and Unreal Engine. Though I think the margin between both is negligible when you are just starting out.\nHow to read this book While reading fiction is very much straight forward, reading books that aim to teach something, can be challenging. I’d encourage you to read through each chapter as a whole and try to understand the concept that is discussed. Then try it out yourself. While I suggest reading the first ten chapters in order, you can take more freedoms after that. It will occur that the chapters are tightly entwined in their topics. If I introduce concepts relevant chapters in different chapters, I will try to always link you to the according passages.\nA note on code If you are an absolute beginner, you might feel that there is a lot going on even in the first chapters. Bear with me. Ignore the aspects of the code you don’t understand and focus on the topics discussed in the chapter. Just copy the rest of the code. By the end of Chapter 9 you should be comfortable understanding all of these things. Just roll with it. On the other side, if you are already versed in a different programming language and think some code examples are messy. And with each concept introduced I try to end up with more readable code and well structured code. But all example have to be well understandable for people just starting out.\nThroughout this book we will approach programming through examples as well as tiny projects to test and apply your knowledge. If you are already completely comfortable with a topic, feel free to skip it and go back to it if need be. The idea behind projects is: Programming is a craft. Many ideas are easy to grasp while reading them, but actually applying them is something different. There is a kind of muscle memory you have to build up. If you have to think about how to write a “if-block”, you lose time to actually think about the higher-level problem. So use these exercises to get up to speed with programming. It will also offer you the chance to try many creative approaches.\nWith all of this out of the way. Let’s go! I hope you enjoy the ride!\n"});index.add({'id':1,'href':'/docs/01_The_Editor/','title':"01 the Editor",'content':" 01 - The Editor Installing Unity The first step on your journey to learn is to download and install Unity. While you could just head to unity3d.com and grab the latest and greatest version of Unity, I would suggest getting the Unity Hub. The Unity Hub will help you manage your projects and the Versions of Unity you have installed on your machine. As you dive deeper and deeper into Unity, the day will come, where you hear of a new feature and you want to explore it. Then you can install any additional version from Unity Hub and manage all the versions of Unity you have installed. It will also remember in which version you opened a project last time. But just grabbing the current version is just fine. If you go for the latter, choose an “LTS” version, like 2019.4. LTS is short for longtime support and has the best chances of getting all bugs fixed.\nI will assume you will manage to download and install Unity Hub yourself. So let’s look at managing Unity Versions and Projects with Unity Hub. On the “Installs” tab, UnityHub will tell you that you don’t have a version of Unity installed. Thus, simply click on the “Add” Button in the upper right corner.   Installed Unity versions in UnityHub   In the next menu, you can just go with the version UnityHub suggests, which will be the latest stable release. On the following one you can make some choices. Unity offers support to export to multiple platforms, but if you don’t want to code for i.e. Facebook, you don’t need to waste space for their Source Development Kit(SDK). But you probably keep the checkbox with “Microsoft Visual Studio Community”. This will be our Code Editor. Click Next and let Unity do its thing.   Additional Options to install   Under “Projects” Unity Hub will show you all your latest projects. If you don’t have one, just press the “New” Button to create One.   Unity Hub Projects Window   In the next panel, you can set the Project Name and the location where you want to store your project. Unity hub will create a folder with your chosen project name. So no need to create that folder yourself. You will also have to choose a Template. “3D” is the default option. You will also have options for 2D and depending on the version you installed for “Lightweight RP / LWRP” or “High Definition Renderpipeline / HDRP”. It could also be, that Lightweight Renderpipeline Unity lists this as “Universal Renderpipeline”. Sooner rather than later this will become the default. Yet we will for now go with the classic “3D” version. Hit create and Unity will take a while to initialize your new project and start up the Editor. Once Unity opens up, you should see something like this:   Standard Unity UI   Unitys “default Layout” is divided in roughly 4 parts.\nThe Hierarchy Window is shows all the Objects that are present in your scene. Using the black arrows you can collapse or expand the hierarchy depending on your needs. On the top you will also see a drop-down arrow, because Unity can open multiple scenes at once.   The Hierarchy View   The “Project” Window holds all Objects inside your project. You can browse this just like any directories in your operating system. You can also create folders to organize yourself. If you were to browse to your project Folder on your hard drive, you would see this structure inside the “Assets” folder. Name all your files and folders from the get go, because things can get messy real quick and not taking care of your Folder-Structure can end being a major source of frustration further down the line. Using right click you can copy, paste, duplicate and even create new Objects. Info about the selected object will show up in the Inspector. (See below)   The Project View   The “Inspector” window shows you information on the selected object. This information comprises so called “Components”. While every Object will have a “Transform” Component the rest of the List will differ. We will look at a lot of components in this book. Just remember where to find them.   The Inspector View   The “Scene” view is your portal to viewing you current Scene. Here you move around and manipulate the objects in your scene using “Gizmos”. To move around in the scene view, you need to remember three shortcuts: Alt + Left-click Drag to rotate Alt + Right-click Drag to zoom Alt + Middle-click Drag to pan the camera   The Scene View   Once you select and Object using left-click a gizmo will appear. The default should be the “move” gizmo. Hover over one of the axis and left-click-drag to move the Object along the selected axis. There are also tools for Rotation and Scale. To switch between the three you could use the buttons on the upper left toolbar. But you shouldn’t. Use the Shortcuts: W - Move E - Rotate R - Scale \rExpand\r↕\r\rIf you wonder how these shortcuts come to be. Why not “R” for Rotate? Because it’s convenient for heavy users. As your thumb will always rest on “alt” for navigation, you will have quick access to the main tools for the editor. Also this corresponds to the Industry-Standard keyboard shortcuts many users know from Digital Content Creation Packages like Maya or Houdini.\r\r\r\rThere is also an alternative way to move around the viewport. If you hold down the right mouse button four squares will appear. Now you can look around by dragging the mouse and move around using the WASD keys. You can try both navigation styles and see which one fits you best.\nIntroducing the Bauhaus When I started writing this “book” I asked myself, what kind of “sketches” or projects I should create. Working in 3D is a complex manner and most of the time relies on external assets. But some of you may not have the possibility to download and install them. And while many readers have some knowledge about how to create 3D assets themselves I don’t want to rely on that. So what to do? Well, the answer was just all over the place. 2019 - the year I started writing - is the “Bauhausjahr”. Or the year which marks the 100th birthday of the Bauhaus movement. And while the Bauhaus isn’t that easy to pin down and I am not an art historian by any means there were things to extract for this book. They focused on reduction to simple shapes and are popular for their Triangle, Rectangle and Circle logo. All shapes we can create in a 3D Software. Most of them come as “Primitives” in a 3D package. Even more so, 3D engines built all objects from triangles! The extreme geometric reduction in the works of the Bauhaus often built on patterns and structures, things we can easily recreate using math. And while all of this was convenient, the thing I consider being most important is experimentation. Many of the teachers at the Bauhaus encouraged their students to experiment. This spirit I’d like to pass onto you. With all the things we create, play around, try things, break things. It is the best way to learn these things. Homage to the Cuboid One teacher at the Bauhaus was Josef Albers. History Albers In his book “Interaction of Color” he describes how he had students collect colored pieces of paper and combine these by layering them on top of each other. The idea was to help students understand how they interact and how they change their appearance based on the colors beneath them. This culminated later in his paintings “Homage to the Square”. (Look it up!)\nThis idea will follow us throughout this book. It will allow us to work quickly, iterate and experiment as much as we can with one simple idea. I also think having to deal with such a simple sketch is great, because it forces you to become creative and iterate and think about what else is possible to based on this idea. It will also work well with coding and you don’t have to install or download anything besides Unity. So I hope you enjoy playing with this as much as I do.\nOther sketches Now I know that there are many people who are not so much into the Bauhaus. And to be honest, while I am fascinated by their ideas, there are many works I don’t “dig” that much. Thus for each chapter I will try to create an alternative project for you to do. The best thing is to check out both! But for these alternative sketches it could be, that it requires you to download assets. All of them will be free.\n“Homage to the Cuboid” in Unity   Homage to the Cuboid   So in this chapter we will create our own “Homage to the cuboid” as shown above. As you can see this will be a rather simple thing to create: We need five cubes and scale and position them. But we will also need a material for each of them. And we need to place our camera.\nBut first things first. Create a new scene using ctrl + n. You can delete everything from the new scene except the camera. This will change the background color, as the light Unity considered being the sun is gone. We will deal with this later.\nNext create two cubes. You can do this by either creating them from the Menu: GameObject ---\u0026gt; 3D Objects ---\u0026gt; Cube or by doing a right-click ---\u0026gt; 3D Objects ---\u0026gt; Cube in the Hierarchy view. In the inspector make sure to set the Translation and Rotation for both cubes to 0. We will then use one Ube as a reference for a perfect cube and the other on we will squash down using the scale tool. I scaled it down to have a scale of 0.1 on the Y-Axis. You can then duplicate this cube 4 times. You can do this in the hierarchy or just press ctrl + d. Then just move them apart to recreate the image above. If you want to do it more mathematically you need to move in steps of 0.225. Once you are satisfied with your result, you can delete the reference cube.\nNow we are missing color. Our cubes are black, because we deleted the only light source in the scene and we don’t want to bring it back! We will use so called “un-lit” shaders for now, as they will allow us to just pick colors. Lights in the scene will not affect these shaders and thus these will be more appropriate for our Josef Albers like studies. To create a material that works fur us, create one from the “Assets” menu or in the project view using right-click ---\u0026gt; create ---\u0026gt; Material. After naming the material we need to change to the before mentioned shader. In the inspector find the drop-down at the top, that says Shader. In it navigate to the UI ---\u0026gt; Unlit ---\u0026gt; Transparent Shader. You will face many options, but we concern ourselves only with the color. Choose one by clicking on the color field.\n  Assign Materials via Drag and Drop   You can then duplicate your materials and choose one color for each cube. To apply the materials to the cuboids you can simple drag and drop them onto the cuboids in the hierarchy or onto the object in the viewport.\n  Assign Materials via Drag and Drop   We will have to adjust our camera to match the example above. If you have Gameview and Scene view open next to each other you can try to push the camera where you need it. But that alone won’t work, because I chose an orthographic view for my sketch. The orthographic view will render all lines in parallel and thus will ignore any perspective. I thought this might work better for our Bauhaus Homage. To change this, select the camera and select “orthographic” from the projection drop-down. And while we are here, we can also change the background color:\nSet the “Clear Flags” to “Solid Color” and then select a Color of your choice. I went with a dark grey. And you’re done!\nProject 1 - Bauhausian Right now your focus should be to become familiar with the Unity editor and how to navigate in the 3D View, if you aren’t already.\nBecause Unity limits you to basic shapes out of the box, you could try to recreate one of the famous Bauhaus paintings. Many of these just use simple shapes, like cubes and circles. You can just use any of the 3D basic shapes as replacements for their 2D counterparts.\nFor Copyright issues I won’t put my recreations here, but I think “Q1 Suprematistic” by László Moholy-Nagy could be something easy to recreate. Or paintings like “De Stijl” by Peter Keler. They both use only basic shapes in different sizes and You pretty much only need to concern yourself with the final 2D output and can ignore third. If you want more of a challenge, you could also try to recreate the “Stacking Tables” by Josef Albers. With these you could also try to create a hierarchy inside the Hierarchy view using drag and drop. This will become handy later.\nProjects Environment Design In this second challenge you have a lot more freedom to create your own. I created and asset pack full of low poly Objects. These should be enough to create small environment scenes. Maybe you can even tell a story with your image. I suggest looking for inspiration and reference online.\nYou can use these Assets in any other scene you want to create.\nExplain how to download an import these assets.\n\rExpand\r↕\r\rLow Poly Models All 3D models comprises three essential elements: Points, Lines and Planes. (Hello Mr. Kandinsky!) But mathematics came in and said: Let’s use our terms and call them: Vertex, edge and polygon. So in 3D the names stuck.\nLow poly objects thus are objects which consist only of a few planes or polygons. This helps with performance on lower end devices but also has turned into a full on art style for illustrations and video games.\nHow to create them? If you are new to the world of 3D, you might as yourself how I created these. I used the free open-source software Blender. You can grab it at www.blender.org. To learn to create objects like these I suggest checking out the YouTube Channel of Grant Abbit. He has some good Videos on creating low poly works.\n\r\r\rTODO Build scene Build Assets\n"});index.add({'id':2,'href':'/docs/02_Moving_Things/','title':"02 Moving Things",'content':" CHAPTER INTRO - REWORK THIS\nThese two thing will perfetly go hand in hand, as Design, as well as Coding are Skills. You can read about them as much as you want, but you will only become good at it by actually designing stuff and actually writing code. This is actually an important point. A lot of the ideas of programming are in their core not hard to grasp. A lot of them are really straight forward. What makes programming complex is dividing bigger problems into smaller problems and even smaller problems. And becoming good at this thoughtprocess takes practice. When I went to Drawing school to prepare for my design studies I didn’t get any better until the moment my teacher Ivan forced me to come back with 100 drawings of simple things within a week. The Website drawabox.com has a challenge of drawing 250 boxes. And for both worlds a great process for starting out exists. In the design world you start out by doing scribbles or storyboards to get an idea of what the result should look like. In coding you should start with so called “Pseudo Code”. Pseudo Code is just a few written lines of what needs to happen. You can then try ordering them in the way the code would require execution, if you can estimate that. These can just look like your average cooking recipe. In essence they are the same. I recommend starting on paper, as technology sadly has a tendency to screw with your thinking process, but it can also be a good idea to bring your pseudocode into your script as a comment.\nFor our “Homage to the Square” experimentation I started with some simple scribbles on what could be things we could easily do with code: TODO INSERT SCRIBBLES AND PSEUDOCODE\n02 - Moving Things Structure of a script So let’s start writing our first script. There are multiple ways to create a script, the one I prefer is creating it via Right-click -\u0026gt; C# Script in the Project View. The advantage here is: you can choose the folder in which the Script should be located and you don’t have to start organizing your files after the fact. But you can also create scripts directly from the Inspector by clicking on “Add Component” and in the search panel simply write the name you want to give to the script. If there isn’t any other component or script with the same name in your project Unity will assume you want to create a script with that name. I called my first script: “MovingCuboids_Lifting”. With your script created just open it using double-click. Your default Code Editor will open. This can take a while depending on your system, especially when you open the editor for the first time. \rExpand\r↕\r\rCode Editors and IDEs The default Code Editor for you probably is “Visual Studio Community Edition” or “Visual Studio for Mac”. These are so-called “IDEs” - Integrated Development Environments. These are powerful tools for editing Code, they can integrate with Unity and come with many advanced features. The downside to them is, they tend to be slow to start up. And on a laptop they can be draining on your battery, as they thoroughly check your code in the background. So if you are on a low end machine it can be wise to look for a “Code Editor”. They are a lightweight alternative, but in comparison lack some advanced features. Great Code Editors are “Visual Studio Code” by Microsoft or “Atom” by GitHub, which is also part of Microsoft. There is also Sublime Text. If you want to check out an IDE that is becoming more and more popular with Unity programmers look out for “Rider” by JetBrains. They also offer the very helpful Plug In “ReSharper” for Visual Studio.\r\r\r\rEvery Unity Script comes with some “boilerplate” Code to get you started. It looks like this:\nusing System.Collections;\rusing System.Collections.Generic;\rusing UnityEngine;\rpublic class MyNewClass : MonoBehaviour\r{\r// Start is called before the first frame updates\r\tvoid Start()\r{\r}\r// Update is called once per frame\r\tvoid Update()\r{\r}\r} The first few lines are “using” statements. All lines in C# that end with a semicolon are considered a “statement”. The “using” statements reference “namespaces” or libraries on your computer into the script. And I think libraries is a nice description for it. Think of it like a book club and you define beforehand which books you want to talk about. It’s tedious to talk about “The Lord of the Rings” if the other person hasn’t read the book. Using these statements you expect Unity know about everything in the UnityEngine itself, as well as the chapters “Collections” and “Collections.Generic” from the “System” book. You can see we can access or require sub-parts using the so called “dot notation”.\nNext up is the class. Every script we write defines a class. You could have multiple classes in the same file, but that is not considered good practice in C#. Classes really are an advanced topic, so for now, let’s just say they bundle a bunch of code together. Take note of the MovingCuboids_Lifting as the class name. This corresponds to the name we gave our script file and they always need to have the same name. If you change the classname, you have to change the filename and vice versa. Everything that belongs to this class is wrapped inside the following curly brackets. Curly braces define a block of Code. You can see this in the Code for the Start and Update Methods as well. All our code belongs inside the curly braces of the class, except for everything related to namespaces.\nMoving on to “Methods”. Start and Update are Methods that Unity recognizes and calls during the execution of the program. The Start function is called first and only once before the program starts running. Here you would define everything you wanted to set up. The Update method is then called each frame and keeps running until you end the program. Here we have to write all our Code that changes or animates over the time of the execution of the script.\n\rExpand\r↕\r\rWhat is a Frame? Images are rendered to your screen, one image at a time. If the distance between two images is short enough, we perceive this as fluid motion. Movies are typically shot with 24 Frames per Second. Unity by default is set up to render 60 Frames per Second, which is the most common refresh rate for Monitors.\r\r\r\rIn general all your code is executed from top to bottom. So if you would move your using statements to the bottom, Unity or your IDE would start complaining.\nThat concludes our first little overview of script structure.\nVariables The first thing Coding Concept we will dissect in detail is “Variables” . Variables are often described as boxes with a name on. You can put stuff in and later retrieve the content of the Box. You can store pretty much anything in variables.\nIn C# variables have a “Type”. This makes C# a (mostly) “type safe” language. To stay with our box example, If you create a box you have to define what kind of things go inside. If you happen to have a heart-shaped box, you can only store heart-shaped things in there. If you create a round box, you can only store round things in it.\nNumbers C# comes with eleven (!) ways to talk about numbers. We will simplify this and only talk about three of them. \rExpand\r↕\r\rNumber-Types, Memory and Performance The reason C# incorporates so many types of numbers lies in all the different use-cases of the language. You might write an application that needs to deal with super precise numbers, or especially large numbers. But these take more space in memory and take longer to calculate. In a game engine like Unity most of the time ultimate precision isn’t important, but performance is. Thus you need to choose the type of number based on your need. You will only need to concern yourself with these in later stages of your programming journey.\r\r\r\rThe first one is integers. Integers contain all “whole” numbers no matter if positive or negative. int integerVariable; This code declares an integer variable with the name “integerVariable”. Right now it holds no value and if would try to access it, you would encounter an error. You can assign values to variables using the = sign. int integerVariable;\rintegerVariable = 1; This would initialize our integerVariable to “1”. We could also do this in just one step: int integerVariable = 1; Assignment is always done form the right side of the = sign to the left. This also means, that any code on the right side will first be evaluated before it is assigned to the variable on the left: int integerVariable = 1+1; `integerVariable’ would now hold the value “2”. Next up are “floats” and “doubles”. Both hold all the non-whole numbers. The difference between the two is, that double use the double amount of memory to save values and can store higher precision values. But this also means that doubles take longer to calculate. That’s why in Unity we typically use floats, unless we absolutely need double precision. So why even TALK about doubles already? Because floats are a little weird\u0026hellip; float floatVariable = 1.1f;\rDouble doubleVariable = 1.1; Look at that code. See something fishy? Whenever we declare a float we have to append the value with a lowercase “f” to tell C# that this is indeed a float-value we want to use and not a double. float floatVariable = 1.1; If we don’t do this, our code will actually not run! The above line will cause an error. The compiler can’t know which value it is, we want to store inside and if he assumes that there is a chance, that he would have to lose data in the process of converting on type to the other, he won’t do it. The compiler will though convert values from one type to the other if he can be sure that no data loss can happen. This is called “implicit” conversion. Implicit conversion happens from integers to floats and floats to doubles and of course integers to doubles. If you want to force conversion for types it’s called “explicit” conversion and we do this using a “cast”: float floatVariable = (float)1.1;\rint intVariable = (int)0.5; You can use this syntax whenever you need to do a simple conversion between values. But note, that while the second statement works, you will have data loss!! So use them carefully!\nStrings Another important Data-Type is strings. Strings contain essentially text. string myString = “Hello! I am text.”;\n\rExpand\r↕\r\rConversion\r\r\r\rWhat needs to be said about strings, really???\nObjects Objects are the last important Data-Type we really need to know about. Objects really is a generalization for many things. Unity comes with a lot of types we will use.\nThe first things we will see are Vectors. vector3 myVector = new Vector3(1,1,1); Vector3s are defined by Unity and essentially bundle three floats in one variable. What’s really important here is the new Keyword. It tells C# to allocate some space in memory for it. So if we create variables for classes, then we need to instance them using the new keyword.\nNow this might sound complicated, but for now just roll with it. We will look deeper into this once we reach the chapter about classes and object orientation.\nOn Pseudo Code Throughout the first chapters we will use our “Homage to the Cuboid” as a starting point for experimentation. This will be a great way to get started coding with very small scripts and also see how just a few lines of code can create interesting results. But before you actually start to code, it’s often a great idea to think about what you want to achieve. There is also great value putting this down on paper. So let’s look at the options we have right now. We have been looking at the transform component in the editor, and this gives us exactly nine values to manipulate: X,Y and Z for each transformation: translation, rotation and scale.\nTODO Sketch of possible actions: So let’s start with translation, bringing a little snake-like movement into our homage. We will aim for something like this:   Cuboids Shifting on the X Axis   Now that we have a creative vision let’s start out with something called “Pseudo Code”. Pseudo code is the idea of writing something code like, but on a really high level. An abstraction which will make it easier to write the code itself later. You can use comments in your code to put down pseudo code. Comments start with double slashes // and everything that follows in that line will ignored by the compiler.\nWe know that we can assign values to variables, and that we only want to change the value on one axis, so let’s use the X axis for now. // x = \nHow do we get the swinging motion? We’ll make use of a useful thing you might remember from school: A sine wave. The sin() method will continuously create a value for us between 0 and 1. Where can we get a continuously growing value? Well: Time! So some simplified code could look like this: //x = Sinus of Time This is actually the basic idea. Now that we have that, we need to figure out how to create the offset between each of the Cuboids. We have to create some kind of Offset for them. But what do we have to Offset? If we Offset X as a whole, we just move the cuboids apart, we actually need to offset the value the sin() function creates and thus need to offset the time value itself. We will also need to be able to adjust this value for each Cuboid individually. // pseudo Code\r//x = Sinus of (Time + Offset per Cuboid) So let’s get coding!\nStarting our first Script So let’s tackle this in the same order as our pseudo code. We need to access the X axis. To access the transform component of the object our script is attached to Unity luckily provides us with a nice shortcut: we can simply use transform. To access sub-components we use “dot notation”, like this: transform // gets the transform component itself\rtransform.position // gets the position of the component as a Vector3\rtransform.position.x // gets the X position as a float. And while we can “get” the X position this way, Unity doesn’t actually allow us to modify the value this way. We need to set the position as a whole and thus as a Vector3. void Update(){\rtransform.position = new Vector3(0,0,0);\r} This would set all our transform values to zero. But as we said, we only want to change the value for the X axis. So let’s make sure that happens, by retrieving the current Y and Z values. transform.position = new Vector3(0, transform.position.y, transform.position.z); This code will set our X value to 0, but retain the current values for Y and Z and thus all our positioning we did in the Unity Editor for these axis will stay put.\nNow to get our motion going, we need to get a hold of time and calculate the sin. Time we can grab from the Time object using Time.time. To calculate a sin from it we can access the “Math” class using Mathf. float sin = Mathf.Sin(Time.time); Here we calculate the Sin value of the current time and store it in a float variable called sin. We can then go on and assign it to our X position in the Vector3: float sin = Mathf.Sin(Time.time);\rtransform.position = new Vector3(sin, transform.position.y, transform.position.z);   Well... it’s a start...   While we are still missing the offset, we also have a very strong movement, and we might want to control both of these.\nPublic and private variables In our pseudo code we found, we need to create an offset for each of our Cuboids. And while we could go ahead an create a script for each of them, that would be very tedious work. It would also be a very awful violation of the “DRY” programming principle: “Don’t repeat yourself!”. Thus what we need is a variable we can adjust per Cuboid.\nWe will put this variable above the Start function but inside the class: public class MovingCuboidsShifting : MonoBehaviour\r{\rpublic float timeOffset = 0;\rvoid Start()\r{\r}\r} Notice something new? We just made our variable public. Public variables can mainly be seen and set by other scripts. But in Unity they also show up on the component in the Inspector.   Variables exposed in the Inspector   So now we can set this value for each Cuboid separately. By default all variables and functions are private and you don’t need to put the private keyword. But sometimes it helps to clarify your code. Serialize Field But, the public keyword does more than just exposing the variable to the Unity Editor. It will allow other scripts in your project to access this variable and read it or change it. And this is a gateway opening up for bugs. Taht’s why we want keep our variables private as possible. To remedy this problem Unity offers the Tag [SerializeField]. It will expose your variable to the Unity editor and keep in private for other scripts. Win - Win! [SerializeField] private float timeOffset = 0; This is the preferred way of working. And while it may seem like unnecessary clutter for now, this will make your life easier down the road. Using this workflow, all the decisions you make regarding making variables public will be conscious.\n\rVariable Scope The last thing regarding variables we need to talk about is “variable scope”. Scope is about which you are able to access at which point in your code. In our code we at the moment have two places in which we create variables. On top of the class and inside the Update loop. Variables you create at the top of the file, or to be precise directly inside the {} of the class have “global scope”. They can be accessed in any function or loop in the class. Variables you create inside a method like Update() or Start() have “local scope”. The can only be accessed inside the method or loop they were created in.\npublic class exampleClass : MonoBehaviour{\rprivate int myInteger = 0; // This is at global scope\r\tStart(){\rprivate int myOtherInteger = 0; // This is at local scope\r\tmyInteger = 1; // This works\r\tmyOtherInteger = 1; // This works as well\r\t}\rUpdate(){\rmyInteger = 2; // This works\r\tmyOtherInteger = 2; // This DOES NOT WORK!! \t} In general you have access to the variables declared on “level”up and at the same level but you don’t have access to the variables at one finer level of detail. They are “out of scope”.\nPutting it in practice Now that we have a value we can adjust, let’s incorporate it into our script: [SerializeField]\rprivate float timeOffset = 0;\rvoid Update()\r{\rfloat sinus = Mathf.Sin(Time.time + timeOffset);\rtransform.position = new Vector3(sinus, transform.position.y, transform.position.z);\r} Now look at the placement of our offset. What do you think would happen if put it outside of the parentheses? All operations in C# follow the basic rules of precedence, but if you’re in doubt about them feel free to just add more parentheses.\nLastly we want to add a scaling factor on the movement range of the cuboids: float movementScale = 0.25f; No we can ask the interesting question where to put this. And there are actually many options, but let’s consider the obvious ones: [SerializeField]\rprivate float timeOffset = 0;\rfloat movementScale = 0.25f;\rvoid Update()\r{\rfloat sinus = Mathf.Sin(Time.time + timeOffset) * movementScale;\rtransform.position = new Vector3(sinus, transform.position.y, transform.position.z);\r} And: [SerializeField]\rprivate float timeOffset = 0;\rfloat movementScale = 0.25f;\rvoid Update()\r{\rfloat sinus = Mathf.Sin(Time.time + timeOffset);\rtransform.position = new Vector3(sinus * movementScale, transform.position.y, transform.position.z);\r} Or the one I actually like best: [SerializeField]\rpublic float timeOffset = 0;\rfloat movementScale = 0.25f;\rvoid Update()\r{\rfloat sinus = Mathf.Sin(Time.time + timeOffset);\rsinus = sinus * movementScale;\rtransform.position = new Vector3(sinus, transform.position.y, transform.position.z);\r} When and where you put your operations depends on the situation, partly depends on style but should mostly be about readability. Which of these would you think is most clear to any other person reading this?\nYou could even go so far as to create a completely new variable for the scaled sinus, which is very precise and thus a very good way to write your code. [SerializeField]\rprivate float timeOffset = 0;\rfloat movementScale = 0.25f;\rvoid Update()\r{\rfloat sinus = Mathf.Sin(Time.time + timeOffset);\rfloat scaledSinus = sinus * movementScale;\rtransform.position = new Vector3(scaledSinus, transform.position.y, transform.position.z);\r} Whichever way you choose. You should now have something like this happening. You can pat yourself on the back. All of this an important first step!   Cuboids Shifting on the X Axis   Rotation While scaling will be very similar to what we just did, rotation can be a little harder. But this is totally dependent on your needs. If you only need to rotate an object around an axis, rotation can be as simple as: transform.Rotate(0, 1, 0); This would rotate the object around the Y axis by a given value.\nWhat you can’t do however is assign a Vector3 directly to the Rotation value. Rotations in Unity are stored in Quaternions. Quaternions take in four values and help in avoiding some problems with rotations in 3D space. To set Rotation values, you would need to use this method: transform.rotation = Quaternion.Euler(0,1,0);   RotatingCuboids   Add Parenting rotation Script here\nProjects Project 1 - Variants To conclude this chapter I again would like to ask you to spend some time and play with the concepts you learned in this chapter some more. Here are some things I came up with you could achieve only using the concepts we introduced so far.   Cuboids Scaling on X and Z     Cuboids moving on the Y Axis   Project 2 - Space Exploration This project is a little more advanced as it uses external models again and you will need to make use of “Parenting” in the hierarchy view. Download the Assets here: Add Assets and results here!\n\u2028- learn \u0026ldquo;parenting” - LowPoly Planets - Transform.Rotate - Transform.Rotate around\n"});index.add({'id':3,'href':'/docs/03_The_Console/','title':"03 the Console",'content':" 03 - Debugging The Console - Your best friend This chapter is a short but important intermezzo.\nMaybe you have already encountered the console. Whenever you write code, your computer does not understand it will tell you so in the console. And worse, it will also block you from running your scene! C# as a programming language is very, very picky about its syntax and what works and what not. “Strongly typed” is the fancy computer science term for that. C# even expects you to care about capitalization. We as humans are prone to making mistakes and thus eventually you will produce an error. If you haven’t, do so. Any typo is good enough: transform.positio = transform.positio + new Vector3(1, 0, 0)* Time.deltaTime;   Error in the Console   As soon as you do this, your computer will complain. But not only will he complain, he will also try to tell you what it is he does not understand: Assets\\Scripts\\MyScript.cs(19,19): error CS1061: 'Transform' does not contain a definition for 'positio' and no accessible extension method 'positio' accepting a first argument of type 'Transform' could be found (are you missing a using directive or an assembly reference?)\nHere, he tells us he knows about Transform but does not understand “positio”. And sure enough he doesn’t.\nHe is also kind enough to print out the line in which he has problems understanding you. So this is the place where you should start your process of debugging. You can even just double-click on the error message and Unity will take you to the line that is causing the error.\nDealing with errors can be very disheartening. But!\u0026hellip; what you always have to remember is that this never means that you are bad programmer. Mistakes happen! Especially in the beginning. They will stay and that’s fine. Everyone knows this happens, and that’s why every code editor will try to do it’s best to prevent you from making errors. Auto-completion for example can help to avoid errors. Any red squiggly line in the code editor is an attempt to notify you, that Unity will produce an Error in the code.\nApart from errors Unity also displays “Warnings” here. Warnings will not break your code. This could for example happen if you use functions that are “Obsolete”. Meaning they are still here for legacy reasons, but will in later Versions of Unity be removed from the code. If you are just playing around, ignore stuff like this, but at least consider what the alternative is.\nWarnings can be manifold, so if you run into one and the displayed message isn’t a helpful try looking it up in your favorite search engine.\nThe power of “Debug.Log” Often in programming we think about what we want to achieve and yet the computer does not do what we want him to. As a beginner we often assume the computer knows something it doesn’t. So we can ask the Computer to tell us what he understands is going on. You could for example print out the value for our sinus Variable at each frame to check if it is staying between 0 and 1. Debug.Log(sinus); If you now run your code and check the Console, see the value printed out each Frame. You can have as many Debug.Log Statements in your code as you want, but they will slow down the execution of your code, so once you don’t need one anymore, get rid of it. They also should not be in your code anymore once you “ship” it.\nIf you have a Debug.Log statement in your code, which you don’t need but think it could be useful down the line, you can also just comment it out for the moment being.\nAnd while this is a helpful way to get a better grasp of your code, you shouldn’t get in the habit of cluttering them all over the place in your code.\nDebug Inspector Now it would be tedious to expose every private variable you want to see on a script via Debug.Log(). Unity also provides us with the “Debug mode” in the Inspector. To enable it, all you have to do is, click on the tiny “burger-menu” in the upper right corner of the Inspector and select “Debug”. Here you can also switch back to the “normal” mode.   Inspector in Debug Mode   As soon as you enable “Debug mode”, you see private variables from your script show up next to the public ones. Unity will then also expose a lot of under the hood options and variables and with these create a lot of clutter inside your inspector. Thus you don’t want this to be the default.\nBreakpoints Besides Debug.Log you can also use so called breakpoints. Breakpoints allow you to specify a line of code inside your IDE and once your program reaches that line, Unity will switch back to the IDE and you can click on all the variables and check their current values. This is a fantastic tool for debugging your code. you can even go into playmode from the IDE. But it is restricted to IDEs, so you will need to use Visual Studio Community or Jetbrains Rider, while Code Editors like Visual Studio Code will not suffice.\nHere is how to use them in Visual Studio Community, which ships with Unity: Inside the Code Editor on the far left of the document window you will see grey bar. You can click on that bar in front of the line you want to use as a breakpoint. At this line a red dot will appear and it will color the line red, meaning it set your breakpoint up.\n  Added BreakPoint in Visual Studio   In the top bar of your IDE you will find a button called “Attach to Unity” and a drop-down arrow right beneath it which will allow you to choose “Attach to Unity and Play”. Select either. If you opt for the first one you have to switch to Unity and manually enter play mode.\nThe code then runs and will stop the moment it encounters the line you specified. Unity will then switch back to your VS Community and mark the line yellow. It will also pop up a few windows on the bottom, i.e. a list of all the variables active and which values are assigned to them. You can explore the object.\n  Hold on Breakpoint   Using the F10 and F11 Keys you can step through the code. Step In will become interesting once we have looked at Methods in chapter five. For now F10 will allow you to go through the code line by line. This allows you to see what is going on inside your script. To stop debugging you can press the red “Stop Button” that appeared the moment you pressed start, or stop the scene inside Unity. I should note, that by default you cannot edit code while debugging is running. And for now keep it that way. Once you have found your problem you can press the red dot again and it will vanish, bringing everything back to normal.\nStill stuck? If you are stuck, there are several places to look for help.\nThe first place you should always check out are the Unity Docs. You can find them at https://docs.unity3d.com. The Unity Documentation is helpful and comprises two different parts. The first part is the manual. It comprises descriptions of all Components and Workflows in Unity and tutorials and Guides on some topics. It also has some great insight about optimizations for your scenes and so on. Be sure to check it out.\nThe other part is the Unity Scripting API. (You can switch between both in the upper right corner.)\nAPI is short for Application programming interface and it’s the things Unity lays open for you to access through code. Like the transform.position. So you could search for transform. The first entry will show you a list of all the things you can access on that component. That is a lot of stuff and you will never need everything. Now think about all other components and think about everything they might lay open. Nobody can remember everything, so it’s great that we can read up on these things.\nIf you choose one of its properties or functions, you can get even more details and in most cases even see example code, which is helpful! You will always find the most recent version of the docs online, but if you have a slow internet connection, you could try Zeal as an offline documentation browser. I have it installed on my Laptop as a great way to search the docs when I’m on the train. You can find it at zealdocs.org.\n"});index.add({'id':4,'href':'/docs/04_UserInput/','title':"04 User Input",'content':" 04 - Conditionals So we know how to code some absolute basic movement. But all of that is built conveniently on the Sin() function and it will just always run, we have no way of interacting with it.\nWhat if we could do things based off of some condition. Let’s say you press a button, move the mouse or tilt your phone?\nThis is where “Conditionals” come in. Conditionals will manage how your code will “flow”, and they belong to a group of programming ideas that people refer to as “Control Flow”. Conditionals in their widest used form come as “if-else” statements. The ideas is, to run code if a certain condition is met - a.k.a “true”. You can then have a statement that defines what happens if the condition turns out not to be true, but that’s not a hard requirement. if(true){\r// This Code would run\r}\rif (false){\r// This code would not run\r} As you can see, the syntax for this is pretty straight forward. You start out with a simple if put true or false in parentheses and add your code in curly braces.\nWhile this is perfectly valid code, it’s also pretty nonsensical. The first condition is true and will always be true and the second piece of code will never run. That makes no sense at all!\nTo make sense of this we need to introduce a new Type: The boolean. Exactly like floats or integers you can create variables for booleans and do “calculations” with them. Yet these calculations need to return true or false. Here are some example: bool myBool = 2 \u0026gt; 1; //returns True;\rbool myOtherBool = 2 \u0026lt; 1; //returns False; You can actually use a few of these operators:\n\u0026gt; greater then\n\u0026lt; smaller then\n\u0026gt;= greater or equal\n\u0026lt;= smaller or equal\n== is equal to\n!= not equal to\nWhile all of these are pretty straight forward I want to point your attention shortly on the “is equal to” operator. It uses double equals. As you know we already have single equals in use to assign values to variables, thus double equals is required for comparison.\nUsing boolean variables or expressions in the parentheses we can make these if statements actually useful. For example we could check if the sinus value on our moving cuboids is negative and then inverse it into a positive number: if (sinus \u0026lt; 0){\rsinus = sinus *-1;\r} In the above code the expression sinus \u0026lt; 0 would evaluate to a boolean of either true or false. Leading to a bouncing motion of the cuboids, as we essentially mirror the negative values of sinus into positive values.   Mirrored X Animation   If-statements also come in two more variants: If-else and If-if else-else. The idea behind these should be pretty clear from the naming itself, but let’s explore them in detail. While a single if-statement will just return to the main-body of code if the condition isn’t met, an else statement will execute another piece of code. Think of an amusement park ride. You are either tall enough and can enter or you are too short and will be send away\u0026hellip; bool isAllowedOnRide;\rfloat height = 150; // in cm\rif (height \u0026gt;= 150){\risAllowedOnRide = true;\rDebug.Log(”You are tall enough. Enjoy the ride.”);\r}else{\risAllowedOnRide = false;\rDebug.Log(”You are too small, kid. Sorry...);\r} This code would make sure either one of both blocks is run. The last option are If-else if-else statements, in which you you could actually have as many else ifs as you like. An example could be a code that checks which team won in a football match, or if the match ended in a tie. int TeamAGoals = 2;\rint TeamBGoals = 0;\rif (TeamAGoals \u0026gt; TeamBGoals){\u2028DebugLog(”Team A Wins!”);\r}else if (TeamBGoals \u0026gt; TeamAGoals){\rDebug.Log(”Team B Wins”);\r} else {\rDebug.Log(”Tie!”);\r} We can of course make use of these in our Homage to decide for one approach or another using these statements. Based on a boolean we promoted to the Editor we can offset the bouncing direction. using UnityEngine;\rpublic class ConditionalCuboidsShiftingXZAppartSimple : MonoBehaviour\r{\r[SerializeField]\rprivate float timeOffset = 0;\r[SerializeField]\rprivate float movementScale = 0.25f;\r[SerializeField]\rprivate bool inverted;\rvoid Update()\r{\rfloat sinus = Mathf.Sin(Time.time + timeOffset);\rsinus = sinus * -1;\rsinus *= movementScale;\rif (inverted)\r{\rtransform.position = new Vector3(transform.position.x, transform.position.y, sinus);\r}\relse\r{\rtransform.position = new Vector3(sinus, transform.position.y, transform.position.z);\r}\r}\r} Here we promote a boolean to the Unity Editor. Booleans will show up as checkboxes. So now we can select in the Editor the Cuboids we want to move along another axis. An example could look like this:   Cuboids shifting on either X or Z   Getting User Input As Unity is in it’s core a game engine one of it’s core features is to do something based on User Input. Every game obviously needs this way of interaction. Unity offers a variety of Inputs. You can check if a button has pressed and get a short pulse like answer, or as for a continuous answer while a button is pressed down. These Inputs will provide you with a simple true or false answer. For more complex input methods like game controllers and joysticks you can receive their current values. You can even grab values like touches and orientation from mobile devices.\nThe most basic Input we can get is “anyKey”. Include Gif here with Button Pressed visualization if (Input.anyKey)\r{\rtransform.position = new Vector3(transform.position.x, sinus,transform.position.z); } Input.anyKey will return true as long as any Input is received. And while it’s fine for our purpose, there really aren’t that many practical uses to anyKey. Most likely you will want to check for a specific button. To ask for these, you also need to choose what kind of event you are interested in. Here are the basic methods to use:\nGetKey() - Returns true while Key is pressed.\nGetKeyDown() - Returns true the moment the Key is pressed down\nGetKeyUp() - Returns true the moment the button is released\nYou will also need to specify the Key you want to check using “KeyCodes”:\nif (Input.GetKeyDown(KeyCode.A){\rDebug.Log(”’A’ was pressed”);\r} To decide for a Key we want to check for we use “KeyCodes”. You can simply provide them in the parentheses. KeyCode.A will check for the “A” Key on the Keyboard. KeyCode.B will check for the “B” Key on the keyboard and so forth. Some of these KeyCodes can be a little unintuitive. I.e. checking for KeyCode.1 won’t work. You have to specify KeyCode.Alpha1. “Alpha” for Alphanumerical. If you can’t seem to find the key you are looking for eith the help of your IDE, check your go to search engine.   Cuboids Shifting on Keypress   Delta Time Take a look back at the example above. That code works fine, but we also kind of introduced a bug into our code. The moment we press the “A” Key all our squares jump and then keep moving. A more pleasing result would be to have them starting of where we stopped them when releasing the button before. So let’s think about our code. Where exactly does the movement come from?\nThe movement is ingrained in our usage of time as a variable. Even worse. It is using System time, and that’s really a place we can’t and don’t want to stop!\nWe need to create our own way of advancing time. We can do that with a simple float variable. private float timePressed = 0; We could go ahead ad add an arbitrary small value to our variable each frame. And we would get a seemingly smooth Animation. This would work fine as long as our machine is able to maintain a constant frame rate. By default it is limited to 60 Frames per Second as a maximum. So worst case, we would get a slower animation on slower computers. But we could disable this upper Limit and on newer computers it could easily run several times faster.\nThis is actually a very common problem in 3D engines. The fix programmers came up with, is deltaTime. DeltaTime is the time that passed since the completion of the last frame. If you add the deltaTime of each frame over the time frame of a second, you should end up with more or less a second. By all means this isn’t perfect, but it’s as good as it gets. And as long your computer dosen’t have any hiccups, this will be fine. if (Input.GetKey(KeyCode.A))\r{\rtimePressed += Time.deltaTime;\r} Now you can use timePressed instead of Time.time in your sin-Function. And the Animation should continue where it left of.   Much Better!   Here is the full code for that:\nusing UnityEngine;\rpublic class ConditionalCuboidsShiftingXAKeyDeltaTime : MonoBehaviour\r{\r[SerializeField]\rprivate float timeOffset = 0;\r[SerializeField]\rprivate float movementScale = 0.25f;\r[SerializeField]\rprivate float timePressed = 0;\rvoid Update()\r{\rfloat sinus = Mathf.Sin(timePressed + timeOffset);\rif (sinus \u0026lt; 0)\r{\rsinus = sinus * -1;\r}\rsinus *= movementScale;\rif (Input.GetKey(KeyCode.A))\r{\rtransform.position = new Vector3(sinus - 0.25f, transform.position.y, transform.position.z);\rtimePressed += Time.deltaTime;\r}\r}\r}\nInput Manager All of the above will pretty much only get us access to keys on the Keyboard. What about controllers and mouse input? For these Unity provides the very convenient Input Manager. It allows you to ask for named input like “Jump” or “Horizontal”. A single axis can then also be controlled by multiple buttons. If you are familiar with video games, you might have seen that you can control a car with “wasd” as well as the arrow keys. In Unity the “horizontal” input will by default react to the “left/right” keys as well as “a” and “D”. It will even react to joystick input from a controller.\nThese possibilities now lead to a different behavior as well. It’s not enough to return a boolean for the horizontal axis, because there are more states to consider then on/off. We have to at least consider three: Left, Right and No Input. To represent this, values will typically be in between -1 and 1. Negative values corresponding to left and positive value corresponding to right.\nTo see which values are read by Unity and how they are configured you need to check the Input panel in the Player Settings: “Edit \u0026mdash;\u0026gt; Player Settings \u0026mdash;\u0026gt; Input”.   The Unity Input Manager   If you pop open one of the Axis you can see which buttons are mapped to the axis and the name connected with it. The name is what you would eventually use in your code to access them: float movementDirection = Input.GetAxis(”Horizontal”); One thing to note: You are asking for the axis by name. You code editor can and will not help you here with spell-checking. If you mis-type “Horizontal”, your code won’t run!\nMouse Input So as I can’t assume you have a game controller laying about, let’s play with mouse Input. Mouse Input is special in a way: You have to some how deal with mouse movement speed.\nThus the Input from “Mouse X” and “Mouse Y” will be the mouse delta, or the distance it traveled during the last frame. We could this create a variant that’s based on the overall speed of our mouse!   Movement based on MouseSpeed   public class ConditionalCuboidsPoppingMouseSpeed : MonoBehaviour\r{\r[SerializeField]\rprivate float movementSpeed = 0.01f;\r[SerializeField]\rprivate float movement = 0f;\r[SerializeField]\rprivate float bounds = .5f +.1125f;\rvoid Update()\r{\rmovement = Input.GetAxis(\u0026#34;Mouse X\u0026#34;) + Input.GetAxis(\u0026#34;Mouse Y\u0026#34;);\rmovement *= movementSpeed;\rtransform.Translate(0, movement, 0);\rif (transform.position.y \u0026gt; bounds)\r{\rtransform.position -= Vector3.up * 1.1125f;\r}\relse if(transform.position.y \u0026lt; -bounds)\r{\rtransform.position += Vector3.up * 1.1125f;\r}\rmovement = 0f;\r}\r}\n### TODO Mouse Input Clicking?\nNew Input System The folks at Unity are currently working on a new Input System, that remedies some of the problems of the current one. This should most likely not concern you too much, but if you think of working on something, that needs crazy input options, you should probably take a look at that!\nProjects Project 1 Your most obvious choice should be to go ahead and create more Cuboids! At least I did. Can you think of a way to recreate these? What would your steps be? The first two should be easy, but how would you solve the last one? Make sure to try these yourself before you peek at the code!   \rExpand\r↕\r\rGist here\r\r\r\r  \rExpand\r↕\r\rGist here\r\r\r\r  \rExpand\r↕\r\rGist here\r\r\r\rProject 2  Bouncing Light in a room?   Project 3 Landspeeder Flight through desert Talk about collsions\n"});index.add({'id':5,'href':'/docs/05_Functions/','title':"05 Functions",'content':" 05 - Methods In this chapter, we will discuss methods. We have been using them for a while now, without discussing them. Methods are a collection of statements that do exactly one thing - or at least they should only do one thing. The Update() method updates all the things you define each frame. The Start() method sets things up in the beginning. Creating or “defining” our own functions will do a lot for us. For one, it will help us avoid repetition in our code. Because of this, it will also help us write way more readable code. You might have noticed that some scripts have become rather confusing. Methods are a great way to bring some order back. Methods also take in arguments they can process to either change or vary what they are doing or return to you a useful value. Methods vs. Functions Many other programming languages call methods “functions”. Many programmers started out in another language and still use the name function when they refer to C#. But they are the same thing and I can’t guarantee that I won’t slip up at one point and use function here or there.\r\rDefining methods To define a very simple method, we need to define two things: a so-called “return type” and name for our method. The most basic return type is void - meaning nothing. You don’t expect to get something returned to you. That is why our Update() and Start() methods use void as a return type. They just do their thing. Methods that typically have a return type are math operations, like a Distance() function. You provide two points as input and expect the distance in return. Let’s look at some examples. void TimeLogger(){\rDebug.Log(Time.time);\r} This code defines a function that returns nothing but prints the current time to the console. You could then call a method at any point in your code, in the same script. Calling a method is as simple as using its name with parentheses but without the return type keyword. So let’s look at a whole script for this:\nusing UnityEngine;\rpublic class LogTime: MonoBehaviour\r{\rvoid Update()\r{\rTimeLogger();\r}\rvoid TimeLogger()\r{\rDebug.Log( “The current timestamp is:” + Time.time);\r}\r} As you can see, we define new methods at the same level as the Start() and Update() method. And you can define them below the line where you call them. Actually, we are defining the Start() and Update() methods in each script. The only difference between our methods and the methods pre-defined by Unity is, that Unity will try to call them automatically during execution, while we have to make sure our methods a called at some point.\nSo how can a simple void method help us with our code? As an example, let’s go back to the “Popping” cuboids from Chapter 04:   public class ConditionalCuboidsPopping : MonoBehaviour\r{\r[SerializeField]\rprivate float movementSpeed = 0.25f;\r[SerializeField]\rprivate float bounds = .5f;\rvoid Update()\r{\rtransform.Translate(0, movementSpeed, 0);\rif (transform.position.y \u0026gt; bounds +.225f)\r{\rtransform.position = Vector3.up * -bounds;\r}\r}\r} While our Update() method is still reasonable in this case, to understand what is going on, we still have to read through rather “low level” code. We can clean this up by using methods. What is the line transform.Translate(0, movementSpeed, 0); doing? It’s moving the cuboid up. So let’s create a method for it. void MoveCuboidUp()\r{\rtransform.Translate(0, movementSpeed, 0);\r} Now we can replace the original line with a call to this function: public class ConditionalCuboidsPoppingRefactored: MonoBehaviour\r{\r[SerializeField]\rprivate float movementSpeed = 0.25f;\r[SerializeField]\rprivate float bounds = .5f;\rvoid Update()\r{\rMoveCuboidUp();\rif (transform.position.y \u0026gt; bounds +.225f)\r{\rtransform.position = Vector3.up * -bounds;\r}\r}\rvoid MoveCuboidUp()\r{\rtransform.Translate(0, movementSpeed, 0);\r}\r} What we are doing right now is called “refactoring”. We are restructuring and often simplifying or de-cluttering our code without changing what it does. Whenever you feel you are done with a script, consider if there is any useful refactoring to be done. We haven’t done it so far because we were missing the proper tools. But doing this helps you to create a beautiful and good to work with code base.\nSo while we are at it? What more can we do? We have a part left where we check for the position and based on that pop the cuboid back down. We could put in a method called CheckBoundsAndPopDown. But wait! Didn’t we establish in the beginning that methods should only do one thing? They should! So let’s split both of them. Easy things first: void PopCuboidDown()\r{\rtransform.position = Vector3.up * -bounds;\r} Now all the methods we have been declaring so far just did things. But how can we simplify the if-statement further? It needs a boolean of true or false to evaluate. This where return types come in. We can make our method return either true or false like this: bool CheckYGreaterBounds()\r{\rreturn transform.position.y \u0026gt; bounds + .225f;\r} Instead of void we define the type we want to return. It’s bool in our case, but could be anything. Then we need to make sure our method contains a return statement followed by the value we want to return. In the upper code we just rely on the evaluation of the statement to return either true or false. With his done let’s look at our Update() method. void Update()\r{\rMoveCuboidUp();\rif (CheckYGreaterBounds())\r{\rPopCuboidDown();\r}\r} Isn’t it a beauty? Consider coming back to this script in two weeks or a month. Checking Update() you know what is going on in the script. You don’t have to work through each line to understand what the whole script is doing. Why would you care how something is moving up or popping down? Or say, you need to change how the cuboid is moving up, you only need to check method MoveCuboidUp() and not all the code in the Update() method.\nRefactoring Tricks Assuming you are using the “Visual Studio Community” Edition that comes bundled with Unity, you can access some a shortcut in the IDE. If you select a line or multiple lines of code you want to refactor into a new method, you can press “Ctrl + .”. VS Community will then as you if you want to “Extract method”. Press enter and a new method including your code will be created. Also, you can now input a name for the method and method and a method call will have the same name.\r\rMethod Arguments The last thing we need to concern ourselves with regarding methods are parameters and arguments. Parameters allow you to “pass” information to the method. We call this information an argument. You’ll see quite a few people using both things interchangeably. A very simple definition and call could look like this: int Add(int a, int b){\rreturn a + b;\r}\rint result = Add(1, 1); // returns 2 To add parameters to a method, we declare their type, an integer in this case, and a name for them in the parentheses we left empty until now. In the method itself, you can use these as normal variables. These are only visible to the method and you can’t use these variables outside the context of the method.\nTo pass information, you add arguments to the function call. Here, this could be literal numbers or any variables that contain an integer. Important is, you have to specify all arguments. You can’t just specify a single integer in parentheses.\nNow you can see that the method we created is rather useless, but I hope it clarified the basic idea. Let’s look at a more advanced example: Insert Fading/Popping Cuboids here While this is the Popping example from before, I introduced some fading towards the bounds. Let’s first look at the beginning of the script: using UnityEngine;\rpublic class ConditionalCuboidsFading : MonoBehaviour\r{\r[SerializeField]\rprivate float movementSpeed = 0.25f;\r[SerializeField]\rprivate float bounds = .5f;\r[SerializeField]\rprivate Color colorToSet;\rprivate void Start()\r{\rcolorToSet = GetComponent\u0026lt;Renderer\u0026gt;().material.color;\r}\rvoid Update()\r{\rMoveCuboidUp();\rif (CheckYGreaterBounds())\r{\rPopCuboidDown();\r}\rif (transform.position.y \u0026lt; 0)\r{\rcolorToSet.a = Map(transform.position.y, -.45f, -.0f, 0, 1);\r}\relse if (transform.position.y \u0026gt; 0)\r{\rcolorToSet.a = Map(transform.position.y, .225f, .45f, 1, 0);\r}\rGetComponent\u0026lt;Renderer\u0026gt;().material.color = colorToSet;\r}\r... So what’s different? First, we now need to create a Color variable, and in Start() we set it to the Color our Object has. Therefore, we can still define the color conveniently via the Material. We need to do this because we can’t directly set the alpha value of a color on the material itself. We can though on a variable. So the last thing in Update() we do, is to update the color.\nIn between do our typical movement and also change the alpha value of our color based on position on the Y axis. ColorToSet.a accesses the alpha component. What do we set it to? We use a method call and pass it five values! So let’s look at the Map() method.\nfloat Map(float value, float oldMin, float oldMax, float newMin, float newMax)\r{\rfloat oldAbs = value - oldMin;\rfloat oldMaxAbs = oldMax - oldMin;\rfloat normal = oldAbs / oldMaxAbs;\rfloat newMaxAbs = newMax - newMin;\rfloat newAbs = newMaxAbs * normal;\rfloat clampedNew = Mathf.Clamp01(newAbs + newMin);\rreturn clampedNew;\r} The Map() method takes in a float value and values for two ranges. With it, you can transfer values from one range to the other. In our example, we have a range between 0.225 for the Upper Mid Cuboid and 0.45 for the Upper Cuboid. During this range we want to fade out the cuboid. But the Alpha values range from 0 to 1. Using this method we can easily convert between them.\nImagine having all this in your code each time we call the Map() method. And yes, we surely could shorten this code. I hope you can see we not only shortened our code, but we also made sure we didn’t repeat ourselves. If now we have a problem with this mapping, we can then easily work through this method and fixing this problem will all the problem will fix all the problems with mapping.\nMagic Numbers In this example, you see some me using actual numbers/values as parameters. I.e.: colorToSet.a = Map(transform.position.y, -.45f, -.0f, 0, 1); While the 0 and 1 are probably fine, because there is no real typical reason to change those, for the others there might be a reason. Those are “magic numbers”. Numbers in the code that magically define how something works or doesn’t. You typically should avoid them at all costs. Create a variable for them! Magic numbers can be a real pain in the a** to debug, especially if you come back to code later.\nI left them, so I could make this point. You shouldn’t!\nColors in Unity We have been working with colors for a while now, but it always was manually selecting them through the Unity Editor. And you will see that this has some advantages to it. But setting and manipulating color has its value, so we will look into it! Color is a complex matter on so, so many levels. This sub-chapter will discuss color on a superficial level and how you could deal with it in Unity. A slightly deeper discussion can be found in Chapter 11. In this chapter, I will assume that you, as an interested person, have some basic knowledge about basic digital color theory. If you do not understand what RGB and HSL are, check the expand directly below.\r\r\rExpand\r↕\r\rThe most important ideas about digital color Everything we are designing in Unity right now is supposed to be displayed on a screen. Screens, in contrast to printed imagery, emit light. As it turns out adding red, green and blue light in the correct proportions will give you white light. Every pixel on your screen consist of these three colors. We thus talk about the additive color. Mixing these three components together will give us a very wide range of perceptible colors to display. For example mixing Red and Green will give you Yellow. Blue and Green will result in Cyan.\nWhile this concept is very nice for computers to understand, we typically don’t talk about color in terms of a combination of red, green and blue. “The suspect wore a 50% red, 50% green and 100% blue sweater.” Yeah, we don’t do that. We say: “The suspect wore a light blue sweater.” Therefore people came up with “HSL”/”HSV” or Hue, Saturation and Lightness/Value. Now we can define a hue around the color wheel, the saturation and its lightness or brightness. From a programming point of view, it also makes some color manipulations easier, because we can access the more “human readable” components directly. \r\r\rColor is its own type in Unity. This means colors need to be created using the new Keyword. The arguments we can pass to the constructor are red, green, blue, and an optional alpha value. The values you need to supply the method will be floats ranging between 0 and 1. Everything beyond 1 will simply be clamped at 1. Color myRed = new Color(1,0,0); // This would be pure red\rColor myGreen = new Color(0,1,0); // This would be pure green\rColor myBlue = new Color(0,0,1); // This would be pure green;\rColor myTransparent = new Color(.5f, .5f, .5f, .5f); // This would be a transparent middle gray Unity comes with some static colors, which you can use for convenience. Color.black for example, could be used just to quickly define a default value.\r\rGiven this, working with colors is pretty much straightforward. A little awkward, is assigning the colors. We need to access the Color Component on the Material Component on the Renderer Component on our object. It’s a long line of code for just a small assignment and it looks like this: GetComponent\u0026lt;Renderer\u0026gt;().material.color = new Color(1,0,0); While we can now change the color, we can just switch it to pre-defined values. How about we try to create a little more flexibility? Luckily Unity provides us with some Methods to retrieve or set colors differently using the Hue, Saturation and Value approach.\nSetting HSV Colors works very similar to creating Colors using the RGBA approach. Instead of red, green and blue, we define values for hue, saturation and value as floats. - Color myColor = Color.HSVToRGB(0,1,1); But it also yields the same results. We can define a color. We just use other means to do so. More interesting would be to actually manipulate colors. Unity does not provide a way to do this out of the box. But we can build our own manipulation tools! float h,s,v;\rColor currentColor = GetComponent\u0026lt;Renderer\u0026gt;().material.color;\rColor.RGBToHSV(currentColor, out h, out s, out v);\rh += 0.05f;\rif(h \u0026gt; 1){\rh - 1;\r}\rGetComponent\u0026lt;Renderer\u0026gt;().material.color = Color.HSVToRGB(h,s,v); The code for this starts growing and will also use some syntax we haven’t seen so far and yet it is rather straightforward. First, we need to declare variables for hue, saturation, and value. All of them will be handled as values between 0 and 1 and thus are defined as floats. Then we create a variable for our current color of the GameObject and retrieve it. Then we use a “static” method on the color class which we pass the current color and tell it to which variables it should assign the three HSV values.\nWith those now assigned, we can manipulate one of those values. Here we choose Hue to shift the color around the color wheel. We also add a Condition to check if we surpass 1, if so, we subtract 1 to make sure we start on the other side of the color wheel again.\nFinally, we construct a new color from hue, saturation and value and assign it back to our Square.   Cuboids Shifting on the X Axis   In the above example, you can see this working on button press. You can see this works relatively okay for monochromatic color schemes. You will find that this approach will fail on other color schemes. But try it! Here is the full code: \rExpand\r↕\r\r\r\r\r\rColor Math Unity also allows for doing basic math operations between Colors. The following Code would give you magenta. Color myColor = Color.Red + Color.Blue; Color math is actually just Vector Math. And Vector Math is nothing else as separating the components and dealing with red, green and blue one at a time.\nGradients   Cuboids shifting, fading and evaluating a Gradient   Another way very pleasing way to work with colors is gradients. While you could define your Gradients through code, we will just look defining them in the editor and then evaluating them at runtime. While this is like shifting colors around, it will also give us more artistic control, which is always nice. To create a gradient, we declare it as a global variable. [SerializeField]\rprivate Gradient popGradient = new Gradient(); We can now create our gradient inside the Unity by clicking on the white color bar in the editor.   Gradient Tool in Unity   On the “Gradient” pop-up window, you can define the gradient by adding new colors on the bottom bar and alpha values on the top bar. In this sketch, I calculated and added alpha separately to the mix. In code, we can then evaluate the color at a position between 0 and 1 or left and right. Color curGradientColor = popGradient.Evaluate(transform.position.y + 0.45f); As you can see, any value can be used to evaluate this. For my sketch, the position in Y makes sense to use. You can see the full code here: \rExpand\r↕\r\r\r\r\r\rRandomness and Noise Noise and randomness are two key ingredients in creating generative art. They allow you to create ever evolving and always changing things. Depending on the depths of layering you create these will virtually never repeat. Randomness will generate completely random values each time you call the method. Randomness has no concept of the previous value or any connection to it. All it knows about it the rage in which it is supposed to generate values. Noise is related to randomness as it returns different values over time. Yet these are not random, they have a pattern and will repeat over time. Noise is great, because it’s very flexible. You can configure it to throw values that seem almost random yet you can also return very smooth values. Here is a simple comparisson of the two:   Randomness and noise   Yet they are also a major source of creating uninteresting and bland work. Especially Randomness. As a designer you want to have control over your work and it’s outcome. You want to transform the randomness to make use of it’s power and yet never bend to its rules. Thus to understand the problems of Randomness lets create a bad example! - Random Color:   Random Color each Frame   \rExpand\r↕\r\r\r\r\r\rTo be fair, probably no one would code this and be utterly pleased with himself. And yet creating colors or movement this way is tempting. But you should resists the urge if you can. But! There are many great thing randomness allows us to do. So let’s first look at how to actually get random numbers back from the computer. float myRandom = Random.Range(0f, 1f); In essence it’s as easy as calling the Random.Range() method and passing it two values for the minimum and maximum numbers you want to get in return. Yet there are a few Gotchas. The Random.Range() method has a few “overloads”. Overloads essentially allows to define one and the same method multiple times, yet the compiler chooses which one of those to use based on the arguments you pass it. And for beginners this really is a nasty trap. Look at these two lines of code: float myFirstFloat = Random.Range(0,1);\rfloat mySecondFloat = Random.Range(0f, 1f); Would you expect the first and second float to return the same of values? Values between 0 and 1? One might think so, but no! The first Random.Range() takes in integers! Okay! So The first one returns integers. It must return either 0 or 1! Wrong again. It always returns 0. Now you might be in a state of confusion. And thats fair. Random.Range() for integers is not inclusive for the higher number. Its “up to but not including 1”. If you wanted to get values between 0 and 1 you would need to pass 2 as the higher value and so forth: int myInt = Random.Range(0,2); // Returns either 0 or 1 Random.Range() for floats on the other side IS inclusive, thus if you pass it 0 and 1 as floats it will include 0 and 1. But you have to make sure to put those fs in there. Technically one would be enough, but I think this is more specific: float myFloat = Random.Range(0f, 1f); \rExpand\r↕\r\rOverloading methods You can create these overloads for methods in your own code as well. Just define two or more methods with one and the same name and different numbers of arguments. But make sure it actually makes sense to create overloads, as you can see, this can lead to some confusion and thus quickly can lead to bugs, especially if you work with other people on a team. \r\r\r\rWith this technical weirdness out of the way, let us look at actually creating more interesting results than the color craze up there. Randomness isn’t really a great choice to create animation, due to it’s in-continuous nature. But it is a great way to do choices. Thus we could change the color of our cuboids based on a random value. But instead of doing this each frame and creating absolutely random colors, we can do it on condition and only choose from a certain set of colors:   Choosing random color from collection   \rExpand\r↕\r\r\r\r\r\rGiven, this isn’t our sweetest result so far, but it is a lot better and feels more consistent than the complete Randomness in the beginning. But we will use the concept of randomness more and more throughout the next chapters.\nNoise We established earlier how noise is different, so let us jump straight into using it. float myNoise = Mathf.Perlin(Time.time, Time,time); As you can see the noise method is located inside the Mathf namespace and it’s called Perlin. The noise method C# implements is actually “Perlin Noise” which was invented by Ken Perlin in 1983. The way this noise works is, we look up a position in X and Y on a black and white noise plane. The result is returned as a float. This means, if you need animated noise, you need to pass values to the method that are changing over time. Like Time.   Noise Shifting   What you can see here nicely is how the patterns in the noise repeats with time. float noiseX = Mathf.PerlinNoise(Time.time * movementScale + timeOffset, Time.time + timeOffset);\u2028float noiseZ = Mathf.PerlinNoise(Time.time * movementScale + timeOffset +.5f, Time.time + timeOffset +.5f);\u2028transform.position = new Vector3(noiseX, transform.position.y, noiseZ ); Getting this kind of animation relies on two kinds of Offsets. The first offset I put as a hard coded 0.5f for the noiseZ value. This will guarantee that the movement will not just happen along one axis. The other offset is a custom offset per cuboid you can set in the Editor. This Offset will create the time offset you can create for the cuboids. You can play around with this value and the order in which you set the offset to create different results. We will come across noise lot’s more over the following chapters.\nProjects Project 1:  The first thing I suggest you do is, go through the scripts you have written so far and refactor them. An for at least a few, try not to rely on the refactoring help of your IDE. Get the concept o writing them engraved into your brain!.\nProjects 2:\n While methods don’t actually allow is to do something utterly new, it allows is creating things that aren’t horribly tedious to do. So here are some more examples for our Cuboid: Go check them out.\nAdd more examples here using methods\nProjects 3:\n Noise Walker Low poly Example More advanced land speeder?\n animated Randomness recreate an image each touch Suprematism can we implement design rules to get “non random results”\n Land speeder with things placed through noise\n   Additional Resources: \u2028- Ari Danish - Working with Noise "});index.add({'id':6,'href':'/docs/06_MultipleObjects/','title':"06 Multiple Objects",'content':" 06 - Multiple Objects Multiple Object Workflow If you followed along with some of the examples, you probably realized we do a lot of manual labor. We deal with the Unity Editor a lot. We apply all the new scripts manually to each Cuboid. Then again programming is a lazy mans art. The less manual labor we have to do, the better. With the concepts introduced in this chapter, we will be able handle lots and lots of objects simultaneously. Hence it will also allow us to create more complex sketches. To do this conveniently in Unity we need to look at three Concepts: 1. Prefabs and Instantiation 2. Arrays and/or Lists 3. Loops In short, we will create objects through Instantiation. We will the use Arrays and Lists to keep track of them and loops to iterate over them. What’s even better is, it opens up a lot of creative possibilities and ideas to talk about! We will also look at interaction between multiple scripts. Finally keywords like private and public will hopefully make more sense.\nPrefabs and Instantiation Instantiation is the process of creating or “instantiating” objects from a script and it is tightly intertwined with the Concept of Prefabs. Prefabs are “prefabricated” Objects we can create through the project view. In most cases these prefabs are the object we want to instantiate through code at runtime. Creating Prefabs is surprisingly simple. Any object you have in your scene can be turned into a prefab. All you have to do is drag an item from the hierarchy into the project view. Go ahead and create an cuboid prefab from any of your sketches.   Creating a Prefab via Drag and Drop   The tiny cube in front of the object turns blue if Unity knows about this object as an Prefab. It’s often advisable to create a specific folder for all your prefabs. Unity will keep all of the components currently attached to the prefab. Any behaviour we have added to a prefab will be there once we create an instance of it. For example a cuboid with a script that makes it move automatically attached to it, will lead to this exact same movement the moment you Instantiate it at runtime. Once you have created a prefab from a GameObject you can go ahead and delete it from the hierarchy, if you don’t need it there anymore.\nInstantiation With an prefab ready, we will need to create a script to actually handle the creation/instantiation of all our cuboids. Because scripts in Unity can’t exists in empty space, we need to create a GameObject to hold our script. Technically any object would work, yet an “Empty Object” would of course be the ideal choice. Empties only consist of a transform component and thus have no visual representation in the scene. Rename your Empty to something like “ScriptHolder” or “Manager”. First we have to find a way to grab hold of our prefabricated cuboid. In Unity all Objects (that inherit from Monobehaviour - we’ll discuss this in Chapter 08) can be referenced as GameObject. So let’s create a variable of type GameObject for our cuboid. [SerializeField]\rprivate GameObject cuboidPrefab; Now go back to Unity and check the Inspector. You will see a field named cuboidPrefab. You can now drag and drop the prefab you created from the Project view into the field on the inspector.   Connecting a prefab to your script   Now the script knows about the prefab. You might argue, that this process feels a little strange, and I am with you. I tend to forget this step and run into an error. But you’ll get used to it! Next we need to actually create an actual instance at runtime: Instantiate(cuboidPrefab, Vector3.zero, Quaternion.identity); The Instantiate() Method takes three arguments: 1. The Object we want to Instantiate 2. A Vector3 as Position in Space 3. Rotation passed as a Quaternion. For now, just use Quaternion.identity;. Quaternions are scary things and Quaternion.identity will place them in the exact state you created the Prefab in, so that’s very likely correct anyway. If you run your scene now, you should have one Cuboid moving around, based on the script you had attached to it, when creating the prefab. Go ahead and duplicate that line and run the code again. It should give you two cuboids and yet you should only see one. Both are created in exactly the same space and size. But you should be able to see two of them in the hierarchy. You could go ahead and change the position at which you instantiate the object, or we could position it after instantiation. To move it afterwards, we need to find a way to access a GameObject after instantiation. To do that we can just assign the created Object to variable the moment we create it: var cuboid = Instantiate(cuboidPrefab, Vector3.back, Quaternion.identity); the ‘var’ Keyword You might stumbled across the ‘var’ Keyword here. You will see code that never uses ‘var’ and code which makes a lot use of it. Generally speaking you should only use it when through the context it is unmistakeable which Type is referenced. This is mostly true for “Object stuff”. To keep it simple for now. As an Example: GameObject myGameOject = new GameObject();\nThis would create a new empty GameObject. But the line of code isn’t a beauty, is it? That’s where var comes in:\nvar myGameObject = new GameObject();\nDon’t worry about it too much for now. This will become second nature over time.\r\rNow we have a variable for our cuboid. This variable allows us to access the the cuboid and all the properties of it, that are actually public. cuboid.transform.position = new Vector3(0,0,0); This is the first time private and public actually become relevant for us in a scripting sense. Try accessing some of the variables we created on the script. You will probably not be able to access them, as we made almost all of them private. The transform component on the other hand is public by default. So to actually recreate our Homage to the cuboid we would need to do this over and over again and then adjusting things and\u0026hellip; nah\u0026hellip; We are not going to do that! As I said before, we want to simplify things! Let’s head into loops!\nFor Loops To be able to handle many Objects (or any kind repeating process) programming languages offer “loops”. Loops are blocks of code that are executed over and over again until a certain condition is met. Maybe the most common implementation of a loop is the “for loop”. For Loops in C# need three things to work: Initializer, condition and iterator. To think of an example, assume having a jar of cookies and you are allowed to eat 50 cookies in a week. So you need to make sure how many you have eaten so far. So you take a piece of paper and start a tally sheet. This tally sheet is your initializer. The Initializer is just creating a variable to keep track of a number. Then each time you want a cookie you check whether you are still allowed to eat a cookie or if you already had 50. That’s the condition. Once you have eaten the cookie you add one to your tally sheet. That’s done using the iterator. Actually eating the cookie is the code in the loop. That’s wrapped in curly braces again. for (int i = 0; i \u0026lt; 5; i++)\r{\rDebug.Log(i);\r} A for loop starts with the for Keyword followed by parentheses. The first thing is our tally list / Initializer. It works exactly like creating any other variable in Unity, but you have to initialize it. What’s also to note is: Counting in computer science almost always starts with 0. Thus we will start with int i = 0! The three parts of a loop are separated by a semicolon. Next up is the condition. Conditions in for loops check if your counter is higher or lower then a certain threshold and if it evaluates to false the loop will stop. Finally, the iterator determines by which value to increase or decrease your tally list. In this case the i++ just means the variable i will be increased by one after each iteration. You could also put i+1. Actually you can advance your initializer in any step size: i + 2, i + 100 or even i - 1. They all work fine. In curly braces follows the code to run. In the above counter we just print the value of our counter i to the console.\nCreate example with for loop here Arrays That’s it for the theory, lets put this into practice. Earlier, when were discussing Instantiation, we said we need a variable to create a reference to our objects. But creating five variables, each to hold a cuboid would be a pain. That’s why we also introduce Arrays. Arrays hold many things of one same type. A list in essence, except that they aren’t really list because list exist as well and\u0026hellip; well\u0026hellip; this is messed up. They are seperate things and we’ll look at Lists a little later.\nAnyway\u0026hellip; Arrays hold things of the same type. Like float or integer. Or GameObject! Creating Arrays is simple. You create them like any variable, but add [] after the type. private GameObject[] myGameObjectArray; Now we have created the Array, but we didn’t initialize it and thus can’t use it. The thing with Arrays is, that they always have a fixed length. So in the moment you initialize the array, you need to specify how many items you want to store in your list. For our cuboid example, it’s as simple as this: private GameObject[] cuboids = new GameObject[5]; We have to specify the length of the Array again in brackets after the type. But what if you wanted to do this based on a variable? You can create the variable for this on global scope and then initialize the array in Start() or Update(). private GameObject[] cuboids\rpublic int arraySize = 5;\r// Start is called before the first frame update\r void Start()\r{\rcuboids = GameObject[arraySize];\r} This construct gives you some flexibility, but you can’t change the actual length of the array. To access things inside an array we use the bracket notation again. Debug.Log(cuboids[0]); This would print the first object in the Array to the console. As we said earlier, counting always starts with 0! Thus myGameObject[1] would give you the second entry and so forth. So now let’s look at actually making use of this: public GameObject cuboidPrefab;\rprivate GameObject[] cuboids = new GameObject[5];\rvoid Start()\r{\rfor(int i = 0; i \u0026lt; arraySize; i++)\r{\rmyGameObjects[i] = Instantiate(cuboidPrefab, Vector3.up * i, Quaternion.identity);\r}\r} This code incorporates everything we have covered so far. We first create a variable myPrefab. We then create a variable for an array of GameObjects and also create a variable for the size of the array. In Start() method we then initialize the array to the size of the variable. Henceforth it can hold five objects right now. But at the moment all slots are empty. Next we need to create a for loop and it’s condition is that our initializer is smaller than our arraySize variable. During the loop w-e access each slot of the list by it’s number, using the iterator. We also use the iterator as an multiplier for the position, thus shifting each object up by one.   Multiple Cubes Shifting   As you can see, the cuboids now move happily along in sync. But they all still have same color and all of them have the exact same offset. Script Communication So what if we want to change the color of these? We need to find a way to access the Color component of the objects. And we have done this before in Chapter 5. But this time we access the GameObject in our array first. for(int i = 0; i \u0026lt; cuboids.Length; i++)\u2028{\u2028cuboids[i] = Instantiate(cuboidPrefab, Vector3.up * (stepSize * i), Quaternion.identity);\u2028cuboids[i].GetComponent\u0026lt;Renderer\u0026gt;().material.color = colors[i];\r} As you can see, we are able to access components on other objects, if we stored a reference to the object beforehand. Here we instantiate the object, and store it directly in a slot in our array. We can then directly use this stored reference on the next line to grab the Renderer on that object and set its color. But how about the time offset? This works exactly the same. Every script we create an add to an object is a component like every other component Unity provides. Instead of Renderer we can now as for the Script we had attached to the cuboid when we created the prefab. This is what it looks like for me: float timeOffset = 0.25f;\rfor(int i = 0; i \u0026lt; cuboids.Length; i++)\r{\rcuboids[i] = Instantiate(cuboidPrefab, Vector3.up * (stepSize * i), Quaternion.identity);\rcuboids[i].GetComponent\u0026lt;Renderer\u0026gt;().material.color = colors[i];\rcuboids[i].GetComponent\u0026lt;CuboidShiftingX\u0026gt;().timeOffset = timeOffset * i;\r} The script I had attached to it, was obviously called “CuboidShiftingX”. In this component I access the timeOffset variable and set it. Now YOU should run into an error here. Thus far, we have all our variables set to private. This will prevent you from accessing and setting this value from outside. To make this possible, go into the script you have attached to the prefab and change the value you want to change to public. Now Unity will grant you access to this variable.\r\rAs you can also see I multiply this with another timeOffset I created in the first line. This will just shift it a little for each cube and not offset it by a whole second. This is also to show explicitly, that you can have the same variable name on different scripts. They are completly different things!   Multiple Cubes Shifting   If you feel that this syntax is complicated, take the time an rebuild some of the sketches we build so far. Also feel free to play around with the number of cuboids you create this way. Make sure to feel comfortable with the idea of Arrays and the usage of i in this context. Arrays are important and we will leverage their power a lot from now on.\nAdd in three examples with Scripts applied to prefabs\nA single script All of the examples above use the idea of having the behavior attached to the prefab itself. To make this even more flexible, we could add our behavior at run time as well. Replace by Gist using UnityEngine;\rpublic class Tests : MonoBehaviour\r{\r[Serialize Field]\rprivate GameObject myPrefab;\rprivate GameObject[] myGameObjects;\r[SerializeField]\rprivate int arraySize = 5;\r// Start is called before the first frame update\r void Start()\r{\rmyGameObjects = new GameObject[arraySize];\rfor(int i = 0; i \u0026lt; arraySize; i++)\r{\rmyGameObjects[i] = Instantiate(myPrefab, Vector3.up * i, Quaternion.identity);\rmyGameObjects[i].AddComponent\u0026lt;Cuboid_MovingUp\u0026gt;();\r}\r}\r} Using AddComponent\u0026lt;\u0026gt;() we can add any script or component Unity offers. Any script you have created in your project is available as a component and can be added this way. So this script could handle all of your variants. All you needed to do was to change the component you add. I hope you can see how much easier this approach is. All you need is a Prefab for your cube without any behavior. Everything else can be managed from this script. Now you could go ahead and even manage the behavior through this script. But that down the line, that really becomes messy. As we have the option to work in different scripts and classes, we should make use of this. Robert C. Martin created the term “Single responsibility principal” for this. And it is a good idea to honor this principle.\nHalf time! Just as a head up. Once you have reached this point of the chapter you have reached half time. And even better. Everything that follows is pretty much just more of the same. Just a little different. So if you are good with everything you’ve read so far, the rest will be a piece of cake! First we will cover variants of the “for loop” and then we will look into Lists - essentially a variant of the Array. We will finish this chapter with a look at multi-dimensional arrays.\nFor-each Loops As I mentioned at the beginning of the chapter, C# offers different variants of loops. They were mostly created to make some common problems more convenient. “For-each” loops work similar to “for” loops, except you don’t need have to bother with the iterator and the initializer. For-each loops iterate over every item in the list and don’t need an iterator. Their syntax is very straight forward as well. private GameObject[] cuboidList = new GameObject[5];\rforeach (GameObject currentGameObject in cuboidList)\u2028{\rCurrentGameObject = Instantiate(cuboidPrefab, Vector3.zero, Quaternion.identity);\u2028currentGameObject.GetComponent\u0026lt;Renderer\u0026gt;().material.color = Color.Black;\u2028}\nYou start with the foreach Keyword. In parentheses you follow that up with the type of object you want to iterate over. We have a list of GameObjects, so we iterate over those. Next we create a name, which allows us to actually access the current GameObject in each iteration. This is what cuboidList[i] would be in “for” loops. Lastly we just specify the array or list we want to iterate over. We just need to add the little word in. All of this actually reads almost like English. On the downside, we are not automatically handed an iterator. Thus if we can not position our cuboids based on that iterator. Here you can see, why there are different kinds of loops. For-each loops are great if you just want to search for an item in a list. Or you want to apply a certain mechanic to all items in the list. But if you want to do this based on the position of the object in the list, the good old for loop is better suited to handle this.\nWhile Loops The last to loops have become more uncommon over time, yet they too still have their uses! “While” loops are the most basic type of loop and essentially just run as long as a condition stays true. Think of the Update function. It loops each frame, but of course has no counter to finish after a certain amount of Frames. That would be silly. Essentially it will loop as long as the game is running. The syntax for while loops is very basic: while(true){\r//Code to run\r} All you need is the while keyword followed by the condition in parentheses. The condition has to evaluate to a boolean. In the above example I set this to true. That would be an infinite loop. true can never just become false. So this will run forever and will freeze your program. So you have to be careful how you construct your conditions with while loops. While(1 \u0026gt; 0){\r//Code to run\r} This again would be an infinite loop, because 1 \u0026gt; 0 will always equate to true. int i = 0;\rwhile( i \u0026lt; 10){\ri++;\r//Code to run each iteration\r} This code would actually work just fine. It’s essentially recreating the for loop. But you could of course use this in cases, when you want to base the iteration on some kind of outside variable. Just make sure to be able to make the condition can become false based on operations inside the while loop.\nBuild a Sektch with While loops\nDo-While Loops There is one last kind of loop which C# offers. The “do-while” loop. As the name suggests it’s very tightly entangled with the while loop. It’s special feature is, that it will always execute at least once, because the evaluation of the condition follows after the first iteration step. int i = 0;\rdo {\rDebug.Log(i);\ri++;\r} while (i \u0026lt; 5);\nExample Project here?? ??!!\nLists While you could say that arrays are essentially Lists in C# they are two slightly different things. And most of the differences matter more to the advanced programmer: Arrays have a fixed size and can thus be placed as one continuous block in memory, while Lists are dynamic and are able to resize. This leads to both of them having advantages in one area over the other. And a good rule of thumb is: If you can get away with an Array of a fixed size, use it! At least in Unity. \rExpand\r↕\r\rMore general C# C# as a language is used for widely different things and many of these don’t require to update at constant 60 FPS. Thus you will see people advise to use Lists over Arrays in most cases. Lists come with more features out of the box and thus are more convenient to use. When performance is not your main concern, that is absolutely correct. If you deal with small scenes I’d say it is also fair to use lists. Once you have to deal with lots and lots of objects and are concerned about performance, definitely use arrays. \r\r\r\rWith technicalities out of the way, let’s look at recreating one of our sketches we built with arrays using lists. private List\u0026lt;GameObject\u0026gt; cuboids = new List\u0026lt;GameObject\u0026gt;(); You create Lists using the List Keyword followed by a type T in angle brackets and the name you want to give to your List. You will also need to create it using the new keyword. Mind the parentheses at the end! To add objects to your List during runtime you can simply use the Add() method provided by lists. cuboids.Add(myGameObject)); An example using Lists and the behavior directly attached to the prefab, would look like this: REPLACE BY GIST\nusing System.Collections.Generic;\rusing UnityEngine;\rpublic class MultiCuboidsLists : MonoBehaviour\r{\rpublic GameObject cuboidPrefab;\rpublic float cuboidDistance = 0.225f;\rprivate List\u0026lt;GameObject\u0026gt; cuboids = new List\u0026lt;GameObject\u0026gt;();\rvoid Start()\r{\rfor (int i = 0; i \u0026lt; 5; i++){\rcuboids.Add(Instantiate(cuboidPrefab, Vector3.up * (cuboidDistance * i), Quaternion.identity));\r}\r}\r} Add Sketch Accessing items in a list is actually done in the same way Arrays access items: Using bracket notation. void Update(){\rfor (int i = 0; i \u0026lt; 5; i++)\r{\rVector3 position = Vector3.left * Mathf.Sin(Time.time * cuboidDistance * i);\rcuboids[i].transform.position = position;\r}\r} As you can see Lists and Arrays are similar. But take a look at all the methods Lists supply. You can not only Add() or Remove() elements from them. There are many useful things, like Sort(), Clear() and even ToArray() methods. These methods and their flexibility regarding length are the main features you should look out for, when deciding between lists and arrays.\nI suggest you play around with both options to get a feel for them.\nMulti-Dimensional Arrays So what if you wanted to position your objects not just in a single axis, but in multiple axis? Now you could probably come up with some way to handle this using ifs or modulos. Or you would just use multidimensional arrays. They work and behave just like one-dimensional arrays, but you will have to nest your loops. You can create as many dimensions as you want, but we will only look at two and three dimensions. private GameObject[,] cuboidArray = new GameObject[5, 5]; This code would create a two-dimensional Array with an array Length of 5 in each dimension. Now most likely you want to assign GameObjects to your Array using an for loop. What you will need to do now is nest two for loops into each other, with a different iterator for each loop.\nConvert to Gist? Replace by script that values single responsibility public int arraySize = 5;\rpublic float offset = 1.5f;\rvoid Start()\r{\rfor (int i = 0; i \u0026lt; arraySize; i++)\r{\rfor (int j = 0; j \u0026lt; arraySize; j++)\r{\rVector3 cuboidPlacement = new Vector3(i * offset, 0, j * offset);\rcuboidArray[i,j] = Instantiate(cuboidPrefab, cuboidPlacement, Quaternion.identity);\r}\r}\r} As you can see, all we need to do is use i and j in our array accessor. To spread out the cuboids, we use i on the x axis for positioning and j for the z axis. The offset will spread them out with some space between them.\n  Multiple Cubes Shifting   Please, be careful with these though! It is really easy to underestimate how many objects you create by just typing in some numbers. An 2D array of 10x10 is a 100 cuboids. An 3D array of 10x10x10 is 1000. Put in 100 and suddenly you expect Unity to create a million cuboids! Now depending on your background, you might think: “A million squares isn’t that much\u0026hellip;”. Think of the way we handle these right now. There is absolutely no optimization done. Each of them is considered equal with all of its components. Thus\u0026hellip; Be careful, save your work early and often before you pump up those numbers. (And now go ahead and crash Unity, as I know you will\u0026hellip;)\r\rAll of this works exactly the same using three dimensions:\nReplace by Gists! Replace by script that values single responsibility\nusing UnityEngine;\rpublic class MultiDimensionalCuboidsRotationStacked : MonoBehaviour\r{\rpublic GameObject cuboidPrefab;\rfloat yOffset = 0.225f;\rpublic int arraySize;\rpublic float offset = 1.5f;\rpublic float rotationSpeed;\rprivate GameObject[,,] cuboidArray;\rpublic Gradient colorGradient;\r// Start is called before the first frame update\r void Start()\r{\rcuboidArray = new GameObject[arraySize, arraySize, arraySize];\rfor (int i = 0; i \u0026lt; arraySize; i++)\r{\rfor (int j = 0; j \u0026lt; arraySize; j++)\r{\rfor (int k = 0; k \u0026lt; arraySize; k++)\r{\rVector3 cuboidPlacement = new Vector3(i * offset, k * yOffset, j * offset);\rcuboidArray[i,j,k] = Instantiate(cuboidPrefab, cuboidPlacement, Quaternion.identity);\rcuboidArray[i,j,k].GetComponent\u0026lt;Renderer\u0026gt;().material.color = colorGradient.Evaluate((float)k / arraySize);\r}\r}\r}\r}\r// Update is called once per frame\r void Update()\r{\rfor (int i = 0; i \u0026lt; arraySize; i++)\r{\rfor (int j = 0; j \u0026lt; arraySize; j++)\r{\rfor (int k = 0; k \u0026lt; arraySize; k++)\r{\rcuboidArray[i,j,k].transform.Rotate(Vector3.up, rotationSpeed);\r}\r}\r}\r}\r}   Three dimensional Array   Examples of possible Things - move through randomly placed Objects - landspeeder with noisy stones on the floor - landspeeder with crazy floors, tunnels\n"});index.add({'id':7,'href':'/docs/07_ClassicGC/','title':"07 Classic G C",'content':" 07 - Classic CC Techniques in Unity If you came here as someone with a background in Processing or p5.js, you might be missing some very common processing techniques, that aren’t too obvious to recreate in Unity. The first thing being the complete handling of the background. In Processing you would handle this in the initial lines of code of your script. In Unity all this functionality is tied to the camera. We will look at setting this up in the editor first. But of course all these things are available via code as well. By default Unity will clear the complete Render Buffer each frame and render the default skybox as a background for your scene. The skybox obviously isn’t the most useful think when you want to create non-enviromental scenes. The most basic alternative to this is setting is a solid background color. This will clear the image buffer with the selected solid color in the field right below the clear flag. As mentioned before, you can of course access all of this via script as well. public class ShapeLerp : MonoBehaviour\r{\rpublic Camera myCamera;\rvoid Start()\r{\rmyCamera = Camera.main;\rmyCamera.clearFlags = CameraClearFlags.SolidColor;\rmyCamera.backgroundColor = Color.white;\r}\r} This of course means, you could also change or animate the clear buffer color to your liking. Shape Lerper Example here\nAnother very popular type of clearing the background is: not clearing. This means the previous rendered frame will stay in the renderbuffer and will only be overwritten in areas the camera deems worthy to behold. What’s worthy? The camera has a settings for near clipping and far clipping. Anything closer that near will not be seen by the camera, everything farther than the far setting will be ignored as well. This range is necessary to make computer graphics feasible. \rExpand\r↕\r\rWhy is it necessary? Think of one meter of distance. How far can we break this up? One meter is 100 cm, or 1000 Milimeters, or 1000000000000 picometers. Femtometers anyone? And now Consider Femtometers at 100km distance. Our Computers just can’t handle such values very well, and even more importantly: not efficient. The solution? Define a range the camera sees and split value we actually can hold in one piece of memory over that range. The larger the range, the less precision we actually get. But most of the time that works out just fine.\r\r\r\rBuilt upon the idea of not clearing the render buffer are built many Processing sketches which involve random Walkers or painting like applications. The main piece of code we need to concern ourselves with is this: private Camera cam;\u2028void Start()\u2028{\u2028cam = Camera.main;\u2028cam.clearFlags = CameraClearFlags.SolidColor;\u2028cam.backgroundColor = Color.white; }\u2028void Update()\u2028{\u2028if (Time.frameCount \u0026gt; 2){\u2028cam.clearFlags = CameraClearFlags.Nothing;\u2028}\u2028} We create a variable to get hold of the Camera in our scene and assign it using Camera.main;. Next we set the clearFlag of the Camera to Solid Color and assign white. We could have done this in the editor as well and if you assigned a background color on the camera it will be overridden by our code. Be aware of that. In the Update() method we simply wait for 2 Frames before changing the CameraClearFlag to nothing. From this point forward we keep the Framebuffer and can override it. \rExpand\r↕\r\rOther Options? Of course you could solve how to create the initial background completely differently. You could have a Plane with an image on it and destroy it after two Frames, or just move it out of the way.\r\r\r\rBut to prove our point let’s recreate another very popular Processing Sketch: The Random Walk. The idea is, to have an Object, often the mere size of a pixel, grab a random number and based on it decide in which direction to move next. public GameObject WalkerPrefab;\u2028private GameObject Walker;\u2028private Vector3 movementDirection;\u2028public float movementDistance = 0.1f;\u2028public float walkerSize = 0.1f; This is just the code for setting things up. We have to create variables for size and movement distance, because we are once again not dealing with pixels, so we want the creative control in the Unity Editor. Walker = Instantiate(WalkerPrefab, Vector3.zero, Quaternion.identity);\u2028Walker.transform.localScale *= walkerSize; This is nothing but the typical initialization of our object in the start function. The interesting part obviously belongs into the Update method: int randomNumber = Random.Range(0, 4);\u2028if (randomNumber == 0)\u2028{\u2028movementDirection = Vector3.up;\u2028} else if (randomNumber == 1)\u2028{\u2028movementDirection = Vector3.right;\u2028} else if (randomNumber == 2)\u2028{\u2028movementDirection = Vector3.down;\u2028}\u2028else\u2028{\u2028movementDirection = Vector3.left;\u2028}\u2028Walker.transform.position = Walker.transform.position + movementDirection * movementDistance; To implement a simple random walk we just generate a Random integer between 0 and 3. Note that the second argument to Random.Range() is exclusive, so we have to add one to it. Then we just define the movement direction based on the random number. Lastly we just add the movementDirection to the current position and assign it. The movement Distance is for us to get some creative control over the outcome and ist most likely tied to size of the Walker we crated. So this is what we got so far: IMAGE OF RANDOM WALKER WITHOUT FADE If you let it walk for a while, you will realize, the walker will sooner or later leave the bounds of the frame. This means we need to decide on way to deal with this. Consider edgecases, what happens out of bounds Next we need to find a way to fade the old frames out over time. In Processing the background takes an Alpha as argument and thus is then written on top of the framebuffer. In Unity the alpha of the background color is just ignored. This means we need to create a transparent front layer ourselves. To do so we create a simple plane just in front of the camera. For the plane we need to create a special material, which is configured to properly override the render buffer: The “Sprite \u0026gt; Default” Material will do the trick just fine. Interestingly enough the alpha value we would want to set is 7. Everything lower than this value will result in not fading out all values properly. But this value was also supposed to be the value to control the speed of fading. To get even more control over the speed of fading we can write a little script, which will enable and disable rendering for the plane in a certain interval.\n3D Scanner Effect 3D Random Walker Random Walker with traces that draw shapes - Random Walker to show fading away stuff over time\nThe Fading Paint Effect Another very popular thing in Processing is to have some kind of Paint effects or even fading paint effects. In the 2D focused world of Processing, all of your shapes are drawn on a plane. This Plane is defined by Pixels. So it is very reasonable to just name the Pixel at whose position you would want to i.e. draw a circle. In Unity on the other hand we are dealing with 3D Space, which means we have to also think about the Z-Axis or the Depth of things. This makes the process somewhat more complex, but will also give us some interesting possibilities to play with. The key to solving this is to shoot an in invisible Ray starting at the camera Center through the Position of our mouse in ScreenSpace. If this Ray is hitting some object, we can retrieve information about the object we hit as well as the hit itself. Most importantly for us, the position at which we hit something. To put this into practice we need to actually hit something. This something will be a plane we position directly adverse to the Camera. We also need to scale it big enough to fill the area our Camera can see. We will then add a Rigidbody Component to it. The intial setup is very similar to our setup for creating the fading random Walker. We just add some variables for our brush. public GameObject brush;\u2028private GameObject currentBrush;\u2028private Camera mainCamera;\u2028// Start is called before the first frame update\u2028void Start()\u2028{\u2028mainCamera = Camera.main;\u2028mainCamera.clearFlags = CameraClearFlags.SolidColor;\u2028mainCamera.backgroundColor = Color.white;\u2028currentBrush = Instantiate(brush, Vector3.zero, Quaternion.identity);\u2028}\nTODO: We can also do this with code: Code\nScanner Effect on a 3D Object which draws shiny/neon spheres\n"});index.add({'id':8,'href':'/docs/07_StartingToDesign/','title':"07 Starting to Design",'content':" The Generative Design pitfall This book claims to be about “Generative Design” and with such about Design in general. And that actually is a bold claim and one I am reaaaaly, really uncomfortable with. While it’s one thing to tell you how programming works, design is a whole different beast. Programming is based on rules. And rules are easy to describe and put on paper. If you forget to put a semicolon in the right place your program won’t run. Design on the other hand let’s you create the most outrageous crap and won’t tell you at all. Even worse, stuff I would think of as outrageous crap other people actually LIKE. There are no hard rules about right and wrong. And the “rules” that actually apply are fluid and evolving. The ideas at the Bauhaus, while interesting and great to study surely can’t be enforced as rules or our surroundings would be boring and bland.\nSo now that we know that design is hard, hard process let me tell you: Generative Design is even worse. While creating with code your logical mind is in the works all the time, and it really just cares about the code and making things work. And once you check your design and you wake the left side of the brain, it will be all sleepy and say: “Say, yeahh I guess, I guess not\u0026hellip;”, but the right side is already all over the place going crazy, just because it works. And believe me I’ve been there. Lots of times! The downer comes once you show it to people and they say: ‘meh’. They can’t see the code. They can’t see the hours you spent learning about loops and functions. They can’t see the time you spend fixing bugs. And sometimes they can’t see this beautiful mathematic idea at the heart of your code. They can’t recognize that. And it’s not their fault. It just means that the visual output you just spend hours on is just not that good. (And I think that is how WordArt came to be in the first place. Programmers creating crazy rainbow colored Fonts, just because the could.)\nDisclaimer So before we move on I just want to get a few things of my chest. I AM one of the people who way too often thought about technical stuff before design. I fell into that pit in almost any project again and again and I still have a hard time not letting those things get in the way of my design. This also means: I am very likely not at all an expert on design and how to apply it. So what follows are merely the basics and you should find input from sources who focus just on design and don’t have their eyes clouded by fancy tech stuff.\nDesign principles So to avoid these moments as best as we can, we will talk about design principles and how to apply them. The most important thing is, that principles are not rules. You can’t enforce them and you shouldn’t. But knowing about them helps a lot, because now you can try to teach you right side of the brain to look for some ideas it can recognize as well, while your left side of the brain get’s the time to actually wake up and have it’s say.\nThe Frame Framing and Composition can be interchangeable terms, but in the context of this book I wanted to talk specifically about the frame first. When you start a painting your work is typically limited by the size of your canvas. When you start sketching frames for a storyboard you typically start with creating a frame. Why? Because every creative decision is based on these borders. How else could you define if something is centered? Well\u0026hellip; the digital world this isn’t so simple anymore. Webdevelopers know exactly what I am talking about. Every website must look good in a variety of formats: Your smartphone, your Laptop as well as the good old CRT monitor that mystically runs in some places. But worse: Consider the smartphone. In horizontal mode you are probably dealing with a 16:9 ratio, in vertical 9:16. Some manufacturers started creating 21:9 displays. With the foldable phones at the horizon, we are back at a 4:3 aspect ratio again, as well as the 16:9-ish ratio in folded mode. All in one device! And while your Laptop may as well sport a 16:9 aspect ratio, resolution and viewing distance might widely vary, again requiring dynamic adjustments to the proportions in the frame, especially if you are dealig eith type. Unity will allow you to support all theses aspect ratios and resolutions. At it heart it really, really doesn’t care where it put’s it’s pixels. And yet it allows you to enforce some rules. You only want to support 16:9 ratios? Done! So you should think about how you deal with this. Where and how do you plan to publish your work? On screens in an exhibition, or maybe projected onto a wall? Or will it be a mobile app people will enjoy on their phones? Are you planning to just release on web? To define your Unity Canvas, Unity provides a dropdown menu in the GameView. TODO INSERT SNAPSHOT. Provided are some common formats like the ones we just talked about. 16:9, 16:10 or 4:3. You can click the “+”-button at the bottom to add your own aspect ratio or resolution. Once added, you can select it, and the camera should instantly switch to that aspect ratio for preview. TODO CHECK HOW TO FORCE ASPECT RATIOS For now I would just choose one aspect ratio for each sketch you create and ignore the problems that arise form having variable aspect ratios as a problem. Once you have an app or program that has to be deployed to devices with unknown aspect ratios you can start considering how to deal with these problems.\nComposition Composition is the art of placing your elements in the frame of your work. It’s about leading the eye of the beholder and making sure the alignment of elements supports the message you try to convey with your work. While you can show the same Write something useful here\n\rExpand\r↕\r\rVR and AR Applications Unity allows you to create Interactive, Virtual Reality and Augmented Reality experiences. All of them force you to think in a completely new and different way about composition, as the viewer himself now, will create the composition. He will decide where to look and where to put his focus and interest. And while in VR you can at least create the whole world around the user, in AR you have to at least consider the user standing in a completely distracting environment. Your storytelling in these situations has to be fantastic, as this will be the driving force in leading the user through experience.\r\r\r\rBalance Balancing is all about creating\nBasic shapes point, line, plane Relationen Structures Colors Textures Animation Iteration and Formstorming Color ###\n"});index.add({'id':9,'href':'/docs/08_ClassesAndOOP/','title':"08 Classes and O O P",'content':" 08 - Classes and Object Oriented Programming Don’t Panic! Friends of mine who studied engineering used to complain about the idea of Object Oriented Programming (OOP) and that it is kind of hard to grasp. I can’t say anything about the programming language or the environment they had to learn in, but inside Unity this is actually rather simple. The thing is: We have been using Object Orientation all the time, you just didn’t realize it. Whenever we created a script, it started with the class Keyword. We just ignored it was there. This keyword means we created a class each time. And classes become objects once they manifest themselves. This means, if you have heard bad things about OOP in the past: Don’t panic. We will just pull some strings together in this chapter.\nBasics of Object Orientation The most important idea of Object Orientated Programming (OOP) is to create clean, modular code which is easy to maintain. We group things in classes and objects which fit logically together and if everything goes well, we never have to touch that piece of code ever again. But if we have to go back in and change it, we have a file that is as small and clean as it can be. Thus we can do our modifications easily. It’s really important to understand: OOP is here to help.\nClasses and Objects In OOP we deal with classes and objects. Classes are the blueprints for Objects, or the idea what the object should be. As soon as we Instantiate it, the class becomes an object. Let’s walk through this by example. Let’s assume we had bike manufacturing and our designer came up with a new concept for a bike. So they defined if it’s a Mountain bike or a racing bike. They also defined the colors, the customer could choose from. And of course how many gears you could have. All of this is the class, the idea of the bike. So we bring it into manufacturing - which would be our equivalent to instantiation - and out comes an object. An Object is the actual version of the bike. You can’t select the color or colors anymore, because all the specifics have been defined during Instantiation. If you need a different bike, you will have to create a new bike - a new object - from the class. Now classes can also define behaviour or methods. We probably want to be able to accelerate. We should also be able to brake, so we don’t crash our nice new bicycle. We might even have some lights on there, so we can see at night. These methods are also defined in the class, and can then be used by the object we created. This idea of packing code together is called “Encapsulation” and is one of the three cornerstones of Object Oriented programming. Encapsulation in short: Put all your code that logically belongs to one object - all it’s properties and all the methods - into one class. An example bike class could look like this, and you will see, this is exactly the same we did all the time.\nReplace by Gist using UnityEngine;\u2028public class Bike : MonoBehaviour\u2028{\u2028public Color bikeColor = new Color(1,1,1);\u2028public int price = 499;\u2028private float currentSpeed = 0f;\u2028private float acceleration = .1f;\u2028private float deceleration = .25f;\u2028private float maxSpeed = 10;\u2028void Update()\u2028{\u2028HandleInput();\u2028Move();\u2028}\u2028private void HandleInput()\u2028{\u2028if (Input.GetKey(KeyCode.A))\u2028{\u2028Accelerate();\u2028}else if (Input.GetKey(KeyCode.S))\u2028{\u2028Brake();\u2028}\u2028}\u2028void Accelerate()\u2028{\u2028currentSpeed += acceleration * Time.deltaTime;\u2028if (currentSpeed \u0026gt; maxSpeed)\u2028{\u2028currentSpeed = maxSpeed;\u2028}\u2028}\u2028void Brake()\u2028{\u2028currentSpeed -= deceleration * Time.deltaTime;\u2028if (currentSpeed \u0026lt; 0)\u2028{\u2028currentSpeed = 0;\u2028}\u2028}\u2028void Move()\u2028{\u2028transform.Translate(Vector3.forward * currentSpeed);\u2028}\u2028}\nInheritance Another concept is “Inheritance”. We have been using inheritance all the time as well: public class MovingCuboid : MonoBehaviour\nThat : right there indicated “Inheritance”. It means our class MovingCuboid Inherits from MonoBehaviour. Inheritance means in short means, you can base classes on other classes. To stay in our own little bike manufacturing shop, you could have a “base class” that holds all the code, that each and every bike has to have. This could be things like name, price or color. But this also could have methods or behaviors every bike must know, like accelerating and braking. The class we have seen previously could be used as our base class. But now we have different customers, with very different requirements. One is just commuting a few kilometers each day. So he fancies a nice, slick single speed bike and will also need good lights for those winter days. The next wants to go mountain biking in the alps over the summer. He wants a versatile gearbox, but sure he has no interest in a dynamo. Those are bikes with very different purposes, but both will end up having a name, a price and a color. Both can inherit these base traits from our bike class, so we don’t need to write that code twice. So we inherit bike using :\n// This code is more schematic, and not an actual implementation\rpublic class SingleSpeedBike : Bike\u2028{\u2028public float maxlightBrightness = 10;\u2028private bool lightOn = false;\u2028public void switchLights()\u2028{\u2028if (lightOn)\u2028{\u2028lightOn = false;\u2028}\u2028else\u2028{\u2028lightOn = true;\u2028}\u2028}\u2028} This can be extremely helpful, as it shortens our code. It also helps us to avoid writing code all over again. It makes things easier and faster to write and to debug. As you can see, on this one, we don’t inherit from MonoBehaviour. We already did so in the base class, thus we don’t have to on the SingleSpeedBike class.\nPolymorphism Polymorphism is the idea that things can be “many-shaped”. Therefore this fancy Greek word. And this is helpful in many ways. Consider this code: private mountainBike myMountainBike = new MountainBike();\rprivate singleSpeedBike mySingleSpeed = new MountainBike();\nAs you can see, once we create our bikes, they become two different types. But what if we would want to create a List or Array of all the bikes we sold. We need to be able to keep track of that, right? Polymorphism to the rescue. Thanks to polymorphism we can use the base class bike as the class we consider to create a list of items sold. List\u0026lt;Bike\u0026gt; MyBikes = new List\u0026lt;Bike\u0026gt;();\rMyBikes.Add(myMountainBike);\rMyBikes.Add(mySingleSpeed);\nPolymorphism also means, that we can override some of the code we wrote in the base class in the child class. This can be useful if you have some code that you need for all your objects, but then there is this one bike, where you want to change it’s implementation. It would be really annoying to remove the code form the base class and put in each child class. And it would also be bad practice to just create a new function that does exactly the same thing. If you look at our base class again. We have that Acclerate() method. If we were to create a mountainBike with some kind of gearbox, we would need be able change the we accelerate right? Somehow our gears need to have an effect on acceleration.\npublic class mountainBike : bike{\rPublic int numberOfGears = 21;\rpublic void shiftUp(){\r// Code for switching the light on and off\r\t}\rpublic void shiftDown(){\r// Code for switching the light on and off\r\t}\rpublic override string advertise(){\rstring ad = “This is our bike” + name + “. It is “ + bikeColor + “ and costs “ + price + “It also has “ + numberOfGears “ gears!!”;\rReturn ad; In our child class mountainBike we declared the advertise function again, but added the keyword override in front. The moment we instantiate our mountainBike the advertise function in the base class is overriden and we can now finally advertise our fancy gearbox!\nConstructors Classes typically come with a constructor. Constructors initialize the object you create and are typically called when you instantiate your object. Why typically? While they are very common in pure C# programming, they are less so in Unity. Unity relies on the Awake() and Start() methods for initialization of values. This at least is true for all classes that inherit from MonoBehaviour and thus rely on Unity functionality. If you don’t need the Unity functionality, because you i.e. just use your class to store some data, then it’s actually no problem to make use of constructors. Constructors them selves are actually rather simple to create. All you need to create is a method with the exact same name the class has: public class Pet\u2028{\u2028public string name;\u2028public int age;\u2028public Pet(string petName, int petAge)\u2028{\u2028name = petName;\u2028age = petAge;\u2028}\u2028} As you can see, you can even pass arguments to this constructor the same way you would pass them to any other method. Now once you want to instantiate a new Pet you can simply pass name and age like this. A little gotcha is the public. If you can’t access the constructor you have a problem. So remember to always have them public. public class NoMonoTest : MonoBehaviour\u2028{\u2028private Pet myPet;\u2028void Start()\u2028{\u2028myPet = new Pet(\u0026#34;Frank\u0026#34;, 6);\u2028Debug.Log(myPet.name);\u2028Debug.Log(myPet.age);\u2028}\u2028} You can also access this data like you would with any other class we have be creating all along, it’s just the initialization that is a little different.\n Fancy Cuboids Spaceship Store instead of Bikes?  "});index.add({'id':10,'href':'/docs/09_DelegatesAndEvents/','title':"09 Delegates and Events",'content':" 09 - More Language Features In this chapter we will look at some other C# features and some loose ends we left along the way, because I didn’t want to bother you with them too early. These aren’t things you definitely need to know from the get go, but they will make you a better programmer. And as soon as you wish to tackle slightly larger projects, make sure to come back here.\nProperties C# properties allow you to specify how other scripts can access private variables in your scripts. This comes in handy, if you want a variable to be able to read a value form outside, but don’t want to be able to set it from outside. Reigning this in is done using getter and setters. These are defined in curly brackets right after the variable name. public int myPublicInt;\rpublic int myProperty {get; set; } If you look at the code we have a public variable and a public property. These two are pretty much the same thing. But we can work with these getter and setter some more. public int myProperty {get; } Now if you try to write to that variable you will run into an compiler error or won’t even be able to compile. So now any Script can read that value, but no script can change the value. You even can’t change it from within the script. But we can manage that: public int myProperty {get; private set;} This will allow you to read the script from outside and manipulate it from the inside. This will allow you to protect your variables from accidentally changing them from some other script. So if you don’t need to set these variables from outside, use this method to prevent bugs. You could of course also use these to prohibit reading and only allow to write from outside. Any combination is possible. So what we have seen so far are “auto properties”. They are shorthand code for something that is usually a little longer. In Unity code you will most often see auto properties, but there are fully fledged properties as well. public string myStringProperty\u2028{\u2028get { return myStringProperty; }\u2028set { myStringProperty = value; }\u2028} This will result in exactly the same behaviour it is just more explicit. But using this larger syntax you can also add additional functionality to your getters and setters. You can change the way you return these values. Thus you could for example check if the value you want to check is actually valid inside your context. public string myStringProperty\u2028{\u2028get { return myStringProperty; }\u2028set\u2028{\u2028if (value \u0026gt; 100)\u2028{\u2028myStringProperty = 100\u2028}\u2028else\u2028{\u2028myStringProperty = value;\u2028}\u2028}\u2028} So you can add any kind of code into the context of getting and setting values. Obviously you shouldn’t overdo this, but the functionality is there. Again, you will mostly see me use the auto properties in Unity, which will help protect variables. But if you come across larger chunks of code that start with get or set, you will know how to interpret these.\nDelegates and Events We discussed earlier how Objects can call functions on other objects. To pick a stupid example: I as a “Salesman” Object could personally call a customer and he could learn from me about all the wonderful things my car offers. I could invoke his “learn” function and the Data I send will be given to him directly.\nBut what if I have a 100.000 customers. Should I make a call to all of them? While that would be a nice move, sending out a letter would be fine too, right?\nAnd that’s what Events are all about. If you have information for many, many customers or classes, you just send them out and anyone who subscribed to the event will get notified about it.\nSo what are delegates and what are Events?\nThe event is the letter you want to send out. The delegate is an agreement between you and the customer how the event is supposed to look like. Say the letterbox. Your customers expect letters in there, but if you suddenly start sending packages, then they can’t be received because they don’t fit the letterbox.\nIn code this mean the delegate is an agreement between sender and receiver what kind of data is send with the event.\nSo this system in itself is useful, but it also comes with some advantages for our code. Once this is set up, any class can subscribe to the event, without us ever changing the code in the class that is invoking the event. So this helps us stay flexible in our code.\nIn larger projects this can also lead to shorter compilation times, which is always a plus!\nHow to setup events?\n Implementing delegates and Events into our projects consists of five essential steps:\n1. Create the agreement about the event a.k.a. the delegate\n2. Create the event based on that delegate\n3. Create the event handler to receive the event\n4. Subscribe to the event\n5. Raise/Call the event\nAs an first very simple example, we will a have a sphere which is slowly shrinking, but once you press a button it will be set to it’s initial Size again. Arguably you could solve this without Events, but bear with me.\nSo we need to create two Scripts. One for the sender of the event and one for the receiver. So let’s just call them Sender and Receiver. So first thing we then need to do is create the agreement or delegate. The delegate belongs into the Sender class. public class Sender : MonoBehaviour\r{\rpublic delegate void ButtonPressedEventHandler();\rvoid Start(){...} The delegate needs to be public so it can be seen by all the other classes. The delegate keyword tells C# that this actually IS a delegate. Now the void is up to us. Essentially we define a function, and if it is supposed to return a value, it can. But we don’t need it, so we’ll go with void. Lastly we define a name for the delegate. Naming follows the same ideas as for methods, but we will use this delegate for handling Events, thus suffixing EventHandler is good practice. This really just defines how the functions working with this need to look like. \rExpand\r↕\r\rDelegates under the hood Delegates under the hood just enable you to store references to methods in variables. Then you can assign methods to that delegate and later call that delegate like a function. You can even add multiple functions to the delegate using += and later call all of them at once. See Microsofts definition here: https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/delegates/\r\r\r\rNext we create the event itself. public event ButtonPressedEventHandler buttonPressed; It is also public, as it needs to be seen by the subscribers. Followed by the event Keyword. The type is the name of the Delegate we just created and finally we give it a name.\nNow lt’s switch over to the recieving Script. Here we first need to create a function that is called when the event is raised. What’s really important here is that this function matches the definition of the delegate we created! void OnButtonPressed(){\rtransform.localScale = Vector3.one * 5;\r} As you can see, the delegate we created has a return-type of void and takes no arguments. The same goes for our OnButtonPressed function. So that’s easy. On to step four!\nNow our receiver needs to subscribe to the event. public GameObject sender;\rvoid OnEnable()\r{\rsender.GetComponent\u0026lt;Sender\u0026gt;().buttonPressed += OnButtonPressed;\r} The first thing we do here is create a reference to the Sender Object as we have done many times before. So we will need to connect these in the Unity Editor!\nThen in the OnEnable() method we get the sender component and look for the buttonPressed event. We then add the OnButtonPressed method to the event a.k.a subscribe it to the event. Form now on, when ever the Event is raised, the OnButtonPressed() method is called.\n\rExpand\r↕\r\rOnEnable() What is OnEnable() and why do we use this? OnEnable() is similar to Start() and Update() one of those predefined functions inside Unity and they run in specific order. Thus there are recommendations on what kind of things you want to call when. If you want to go down the rabbit hole: https://docs.unity3d.com/Manual/ExecutionOrder.html\r\r\r\rSo how to raise the event? We of course need to do this back in our sender Script. And all we need to do is call the event like any other function we call: buttonPressed(); So far so good. But let’s embed it into our code. void Update()\r{\rif(Input.GetKeyDown(KeyCode.A)){\rif (buttonPressed != null){\rbuttonPressed();\r}\r}\r} In Update() we check for someone pressing the “A” key. Then we check if buttonPressed is not Null. If this returns Null it means button pressed has no subscribers and then there is no need to actually raise the event. Worse! If you don’t check for this, it will actually throw an Null reference exception at runtime!\nBut if it’s not null, this will actually run just fine!\nThis is awesome. But let’s clarify a bit more why this is awesome. Now we can add as many functions to this event as we want! Let’s just create a function to randomly color our sphere: void OnButtonPressedColor(){\rthis.GetComponent\u0026lt;Renderer\u0026gt;().material.color = new Color(Random.Range(0f,1f), Random.Range(0f,1f),Random.Range(0f,1f));\r} We can then just subscribe this to the event as well: sender.GetComponent\u0026lt;Sender\u0026gt;().buttonPressed += OnButtonPressedColor; Now we didn’t have to change anything in the sender class. The sender class doesn’t care or even know about what we did here! You could now easily add new classes that also implement this and would never again need to change the sender class.\nUnsubscribing from events Now one thing that would be considered good practice is unsubscribing once your object get’s disabled or destroyed. That is as simple as subscribing actually. Just use -= in OnDisable(). void OnDisable(){\rsender.GetComponent\u0026lt;Sender\u0026gt;().buttonPressed -= OnButtonPressed;\rsender.GetComponent\u0026lt;Sender\u0026gt;().buttonPressed -= OnButtonPressedColor;\r}\nStatic events While all of this is fine, it’s also a lot of stuff to take care of. So let’s look into simplifications, now that you know the full version of it. The easiest simplification is to make your event static.\nThis allows us to not create an object Reference in the receiver first. You can just subscribe to the event calling the class like this: Sender.buttonPressed += OnButtonPressed;\nActions We can even go further and reduce the delegate creation and event creation into one line. To do this we first need to import the System namespace. using System;\nThen we need to change the way we declare our delegate: public static Action buttonPressed; This will now be enough and an we can subscribe directly to this Action. In case you need to add parameters to your events, the syntax changes and you need to provide them in \u0026lt;\u0026gt; braces after the Action keyword. The following code would expect an integer and float as input values. public static Action\u0026lt;int, float\u0026gt; buttonPressed; And thus you need to supply values as arguments when calling the function!\nAs you can see Actions can simplify delegates and events a lot. But I wanted to make sure to show you the whole process, so you are able to read code that uses the extended method.\nTODO - Example Multiple Classes - Example with a return type - Example with Func instead of Action\nPojects  Death Events and delegates Cuboids to interact with   "});index.add({'id':11,'href':'/docs/10_BestPractices/','title':"10 Best Practices",'content':" 10 - Problem Solving and well designed code  Designing Code  Before we dive deeper into considerations of design, let’s take a very short break and discuss designing code. As with design, there are often different ways to solve the same problem. You soon will, or already have seen, me writing code that you would have approached differently. And it is possible that your solution is better. (And please let me know if you think I do some stupid stuff!! “LinkToContactSheet”) But maybe it’s just a different approach to the problem. Five programmers will solve the same problem in 5 different ways. And that’s fine.\nHowever, there can also be differences in the effort put in to solving the problem. Yes, you can solve many problems naming your variables x1 to xn. But will you remember what x1 and x2 were, when you look at your code one month later? You probably can’t. You will have to read through that and figure out what these variables were used for.\nThis chapter is devoted to some basic conventions about writing beautiful code. We will just touch the basics, as you could write books about how to write well designed code - and people did. Most notably, Robert C. Martin. He describes many of the following ideas and concepts in his book “Clean Code” in great detail. So if you want to further you understanding after this chapter, check it out!\nUnderstanding well designed code So how do you recognize and write well designed code? Well designed code is easy to read and understand for other human beings. The code in the Unity Documentation is a great example. Most examples are short yet on point. They are easy to skim through and learn from. This comes down to many things:\nThe formatting is precise and blocks of code are indented to make the structure of the code recognizable just by skimming over it.\nThe variable and function names are well chosen. If you had no idea about coding and someone would ask you what the Translate() method does. What would have been your guess? Rotate() and RotateAround()? As those are examples they have some minimal comments that remind you of the documentation when you copy and paste them into your project. They are a fantastic learning resource.\nBut you will also find great examples on GitHub and other code resources. Whenever you feel the code you see is readable and you can easily understand it, you have some good code in front of you. Ending up with good code Now we know what well designed code looks like. But how do we end up there?\nThe first advice I’d like to give is once again: Start on paper! Thinking about what you want to do with your code is essential. Going straight down the road to code is problematic, as it clouds your thinking. Having a list of things your code needs to do on paper will also be a great reference for choosing the variable and function names. With time you can more and more reduce this way of working, but as a beginner it helps a lot! And for more complex work it’s a valuable way of working as a professional.\nYou also should not abandon your code as soon as it runs. When you get into the coding frenzy, especially as a beginner, you will try things, comment stuff out and overall have not the knowledge to write beautiful code just like that. And that’s just fine. But don’t abandon it the moment it runs. Take the time to clean it, massage it and perfect it. There is nothing worse than a piece of code you leave behind, knowing it is a mess. You will never want to come back to it and fear the day you have to. Clean up after you’re done and safe your future self a lot of work!\nBut don’t over do it. Clean and minimalistic. Just because you know how to write properties, you don’t have to use them if a simple public variable does the trick. For now you are in a game engine and not writing car automation systems.\nElements of good code: Code Conventions\n First, naming conventions are team-specific. If you as a team have a good reason to deviate from the language specific naming conventions, then do so. It’s more important to have a consistent code base to work on, then to follow what everyone else is doing. Yet there are some rules or best practices that spread over the use of a language and it makes sense to abide to these.\nMicrosoft has a C# Guideline for this online, but it boils down to:\n- non-static variables/fields and parameters are camelCase\n- everything else is PascalCase\nSo that’s easy to remember, but just have a look at this code as an example.\nnamespace MyPascalCaseNamespace{ class MyClass{\nCode Example? So\nElements of good code: Naming One of the most important parts in writing good code is the naming of your variables, methods and classes. It all comes down to one thing: use meaningful names. If you had to read the code as a stranger for the first time, would you understand what it does? This means radius is better than r. If you have a circle and a sphere in your code circleRadius and sphereRadius would be good choices. Don’t shy away from of long names. By default your code editor is Visual Studio, so you have auto-completion as a feature built in. If a long name is more precise, use it!\nWhile a long precise name is fantastic, try not to clutter it with useless information. radiusOfTheCircle would just add useless clutter. So as precise as necessary and as short as possible is good advice to give.\nFor variables use adjectives, for methods you should use verbs and for classes nouns. This makes sense in the way they are used in your code. When you choose a word for a concept, use the same word for the same concept every time. I.e. you write a custom trigger system, all your functions should use the word trigger in them and not use event or something like that.\nAgain this can happen when you are immersed into your coding flow, but when you are done, take a step back and take the time to rename those functions and variables. It will make your life and that of others so much, much easier!\nElements of good code: Functions The one hard rule for methods should be: Do one thing. While it sounds very obvious, we often tend to do another thing in the same method. Take a method named createSphere(). It should create a sphere. It shouldn’t color them randomly as well. That’s a different method. It should just do what the name of the method suggest it does.\nNow you might say, everyone sees that the sphere is i.e. red. That’s true, but most problems aren’t that drastically visual. For other users of your methods this can end badly! Thus, if you realize your method does more that one thing, refactor it.\nFor method arguments you should try to reduce them as much as possible. There are methods that need to take three variables. Think of a Vector3 for example. You just have to assign x, y and z. But in most cases you can avoid this. If you have to pass more than one or two variables to a method, think about it. Can you clean this up more?\nElements of good Code: Comments In a perfect world you would not write a single comment in your code. But we all know the world isn’t perfect. So you will need to write them. But before you write a comment, ask yourself: Is there a way to change my code, to make it so well designed, that nobody would need to read this comment? Maybe by clarifying a function name?\nWell, it’ wasn’t possible\u0026hellip; Too bad. Then add your comment above the section you want to comment. Make it short and clear and you are good to go.\nIf you come across comments in code you read, maybe even your own code, ask yourself: Is the comment describing or adding useful information to the code that follows the comment?\nIf not, remove it. The thing with comments is: They age terrible. If you start with a comment for a function and then later change that code because the way you implemented it changes, you might not think about changing the comment. It just happens. So always consider if the comments tell the truth.\nBibliography: - “Clean Code: A Handbook of Agile Software Craftsmanship,” by Robert C. Martin - Microsoft Framework Design Guidelines (https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/) - Unity Documentation Optimization "});index.add({'id':12,'href':'/docs/11_StartingToDesign/','title':"11 Starting to Design",'content':" Disclaimer So before we move on I just want to get a few things of my chest. I AM one of the people who way too often thought about technical stuff before design. I fell into that pit in almost any project again and again and I still have a hard time not letting those things get in the way of my design. This also means: I am very likely not at all an expert on design and how to apply it. So what follows are merely the basics and you should find input from sources who focus just on design and don’t have their eyes clouded by fancy tech stuff.\nThe Generative Design pitfall This book claims to be about “Generative Design” and with such about Design in general. And that actually is a bold claim and one I am reaaaaly, really uncomfortable with. While it’s one thing to tell you how programming works, design is a whole different beast. Programming is based on rules. And rules are easy to describe and put on paper. If you forget to put a semicolon in the right place your program won’t run. Design on the other hand let’s you create the most outrageous crap and won’t tell you at all. Even worse, stuff I would think of as outrageous crap other people actually LIKE. There are no hard rules about right and wrong. And the “rules” that actually apply are fluid and evolving. The ideas at the Bauhaus, while interesting and great to study surely can’t be enforced as rules or our surroundings would be boring and bland.\nSo now that we know that design is hard, hard process let me tell you: Generative Design is even worse. While creating with code your logical mind is in the works all the time, and it really just cares about the code and making things work. And once you check your design and you wake the left side of the brain, it will be all sleepy and say: “Say, yeahh I guess, I guess not\u0026hellip;”, but the right side is already all over the place going crazy, just because it works. And believe me I’ve been there. Lots of times! The downer comes once you show it to people and they say: ‘meh’. They can’t see the code. They can’t see the hours you spent learning about loops and functions. They can’t see the time you spend fixing bugs. And sometimes they can’t see this beautiful mathematic idea at the heart of your code. They can’t recognize that. And it’s not their fault. It just means that the visual output you just spend hours on is just not that good. (And I think that is how WordArt came to be in the first place. Programmers creating crazy rainbow colored Fonts, just because the could.)\nDesign principles So to avoid these moments as best as we can, we will talk about design principles and how to apply them. The most important thing is, that principles are not rules. You can’t enforce them and you shouldn’t. But knowing about them helps a lot, because now you can try to teach you right side of the brain to look for some ideas it can recognize as well, while your left side of the brain get’s the time to actually wake up and have it’s say.\nThe Frame Framing and Composition can be interchangeable terms, but in the context of this book I wanted to talk specifically about the frame first. When you start a painting your work is typically limited by the size of your canvas. When you start sketching frames for a storyboard you typically start with creating a frame. Why? Because every creative decision is based on these borders. How else could you define if something is centered? Well\u0026hellip; the digital world this isn’t so simple anymore. Webdevelopers know exactly what I am talking about. Every website must look good in a variety of formats: Your smartphone, your Laptop as well as the good old CRT monitor that mystically runs in some places. But worse: Consider the smartphone. In horizontal mode you are probably dealing with a 16:9 ratio, in vertical 9:16. Some manufacturers started creating 21:9 displays. With the foldable phones at the horizon, we are back at a 4:3 aspect ratio again, as well as the 16:9-ish ratio in folded mode. All in one device! And while your Laptop may as well sport a 16:9 aspect ratio, resolution and viewing distance might widely vary, again requiring dynamic adjustments to the proportions in the frame, especially if you are dealig eith type. Unity will allow you to support all theses aspect ratios and resolutions. At it heart it really, really doesn’t care where it put’s it’s pixels. And yet it allows you to enforce some rules. You only want to support 16:9 ratios? Done! So you should think about how you deal with this. Where and how do you plan to publish your work? On screens in an exhibition, or maybe projected onto a wall? Or will it be a mobile app people will enjoy on their phones? Are you planning to just release on web? To define your Unity Canvas, Unity provides a dropdown menu in the GameView. TODO INSERT SNAPSHOT. Provided are some common formats like the ones we just talked about. 16:9, 16:10 or 4:3. You can click the “+”-button at the bottom to add your own aspect ratio or resolution. Once added, you can select it, and the camera should instantly switch to that aspect ratio for preview. TODO CHECK HOW TO FORCE ASPECT RATIOS For now I would just choose one aspect ratio for each sketch you create and ignore the problems that arise form having variable aspect ratios as a problem. Once you have an app or program that has to be deployed to devices with unknown aspect ratios you can start considering how to deal with these problems.\n\rExpand\r↕\r\rVR and AR Applications Unity allows you to create Interactive, Virtual Reality and Augmented Reality experiences. All of them force you to think in a completely new and different way about composition, as the viewer himself now, will create the composition. He will decide where to look and where to put his focus and interest. And while in VR you can at least create the whole world around the user, in AR you have to at least consider the user standing in a completely distracting environment. Your storytelling in these situations has to be fantastic, as this will be the driving force in leading the user through experience.\r\r\r\rComposition and Balance Composition is the art of placing your elements in the frame of your work. It’s about leading the eye of the beholder and making sure the alignment of elements supports the message you try to convey with your work. While you can show the same Write something useful here\nBalance Balancing is all about creating Symmetrical, Asymmetrical, Radial\nRule of thirds\nBasic shapes point, line, plane Relationen Structures Colors Textures Animation Iteration and Formstorming Color A word on color  we now have an animated Version of these squares, but Josef Albers was obviously concerned with colors in these things at the Bauhaus he sure wan’t the only one, Johannes Itten as well Before them Goethe took a shot at Color theory while they had their problems, to fix the rise of the screen comes with it’s own very specific set of problems with this also came complex ideas like Gamma Correction and Linear Light it also came with color spaces it even got worse, if you design for the screen you essentially design for Your screen! Even if you have to the perfectly calibrated monitor, your enduser does not. Their Computers come with stuff like “Night Light” which shifts colors towards red at night The world of Color is imperfect! The world of Color is also very, very subjective! They are changed by cultural background and personal preference. A color scheme that resonates strongly with one person might not so much with another person.\n Color Wheel\n Color combinations\n where to inspiration (nature)\n good color is hard to master and is learned by experimentation\n  Designers which I think work great with color: James Turell Colorlisa.com\n###\n"});index.add({'id':13,'href':'/docs/12_UserInterfaces/','title':"12 User Interfaces",'content':" 13 - Animation Animation is huge topic. Animation can be about bringing characters to life or about just creating a pleasing transition between two pages in app. Animation can be about huge strides and yet shines when the most subtle feelings of an character\nPhilisophical shit about Animation\nAnimation in Unity Using Unitys Animation System can be utterly simple, but also scales very well into extremely complicated Animation of Characters and blending between Animations based states. If you are familiar with Animation systems in other software like After effects, Maya or Blender, you are probably used to just selecting an object and being able to add Keyframes. This doesn’t work in Unity.\nAnimations in Unity come with two components: An Animation Clip a.k.a the actual animation and an Animation Controller. The Animation Controller can handle multiple Animations and switch or transition between Animations.\nWhile this might seems complicated in the first place, it’s actually a fantastic system. It makes all your animations easily reusable. Once set up, you can use it over and over again on any object that has the same components applied to it.\nYou also don’t HAVE to concern yourself to much with the animation controller when starting out, because Unity can handle it’s creation for you. And as classics are always a good way to get started: Let’s create our first bouncing ball!\nTo get started just add a Sphere to the scene and zero out it’s transform. You can also create Cube as a floor to bounce around on. Next we need to open the Animation Window: “Animation \u0026mdash;\u0026gt; Animation Window”. With the Sphere selected the animation window should offer you a button to create an Animation. Animation clips are actually physically saved as individual objects on your Hard drive. You could copy them to a different project, if you wanted to. Talk about re-usability!\nIf you create Animations this way Unity will automatically create an Animator Controller as well for you and apply the Animation. So you really don’t have to care about it for now, yet you will find it applied to the Sphere.\nTo start animating, we need to add Properties we want to animate. Once you click the button you are presented with all the components that are currently applied to the sphere that actually have properties that can be animated. From the transform component go ahead an add the Position and Scale parameters using the “+” icon.\nUnity will by default create an animation that does nothing and is one second long.\nTo change the values drag the playhead to the position, where you need Keyframes and add them using rightclick. You can only change the values of keyframes that are at the position of the Playhead. If you want Unity to automatically set keyframes while editing, press the little red recording button. Because you can easily make mistakes in recordig mode, the timeline head will turn red, as well as the values in the inspector. You can also use the gizmos in the editor to animate your object.\nWhile Unity will create some default interpolation for us while adding Keyframes, it’s very likely that we want to tweak them. In the lower bar of the Animation window you can switch between the Dopesheet and the Curves view. For finer control over you animation the Curves view is an indespensible tool to create great animations.\nUnity will show you the interpolation curves it created for you and you can just go ahead and grab the Keyframes. Using the handles you can adjust you interpolation between the keyframes. If you need hard changes in your animation you need work with broken handles. to switch the handle types, just select the Keyframes you want to affect and press select the type you need using the righclick menu.\nWhile you can always go in and and preview you current animations using Animation window, you also just switch to Playmode. The way we created the animation, Unity has set this up for us as an looping Animation.\nSo here is the result and the curves for my super simple bouncing ball: Todo Bouncing ball and curves \rExpand\r↕\r\rIf you are completly new to animation and want to get into I suggest looking up “The Animators Survival Kit” by Richard Williams. “The Illusion of Life” by Frank Thomas and Ollie Johnson is another great book to look at. They first introduced the “Twelve principles of animation”. To get an overview you can also do quick search on YouTube.\r\r\r\rBecause animation is hard work, Unity has at least some shortcuts set up for us, to make our lives easier: |Shift+Comma|First Keyframe| | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | |Shift+K|Key Modified| |K|Key Selected| |Shift+Period|Last Keyframe| |Period|Next Frame| |Alt+Period|Next Keyframe| |Space|Play Animation| |Comma|Previous Frame| |Alt+Comma|Previous Keyframe|\nSo now that we know how to actually create Animations, let’s look at how they are actually set up and connected on the gameObject itself.\nIf you take a look at your sphere, you will see, that the component that’s actually applied to the sphere is an “Animator”. The Animator is responsible for handling the Animation of your object and requires and Animator Controller to work. You might think this is an unnecessary step, but it is also handling things that only become relevant in more complex scenarios, like applying Root Motion. (Try it, it’s fun.)\nThe first parameter the Animator supplies is a Controller. Right now that’s probably named “Sphere”. Or if you have renamed your Sphere before creating the Animation, it’s probably named like that. If you double-click that Controller Unity will jump to the Controller in the Project View. It should be in the same folder as the Animation Clip you created. Double Click on that and the Animator Window should pop up.\nHere you will see a left side with an entry called Base Layer as well as a Blueprint like view with three elements inside. This is a “State Machine”. It handles in Animation the current object is currently in, and if and how this object can transition to another “State”. By default you be presented with three states. “Entry”, “Any State” and a state named after your Animation Clip. The Entry State will be linked to your animation clip. This shows you that, as soon as the object becomes active the animation clip will be played. If you switch into PlayMode, you will see also see progress bar appear on the State that is currently playing.\nGo ahead and create a new animation clip, or just duplicate the one you have. You can drag an drop it in to the state machine as well. As you will it will not have any connection by default, so we need to set it up. Select either one of the Animation clips and go “RightClick \u0026mdash;\u0026gt; Make Transition”. And then click on the object you want to transition to. If you want to be able yo switch been both animations, you have to create transitions in both directions. Switch into playmode to see all of this working.\nNow depending on the animation you have set up, you might notice that your animations look sluggish. The first time i did this I got really confused, about what happens. Because this whole system is set up to also manage Characters and these states could be things like jumping, running or sitting, Unity by default applies a blending operation between the states.\nTo see this select one of the arrows a.k.a transition and check the inspector. Here you will see a transition timeline. If you move the left arrow on the playbar directly next to the right one, you will be able to move the lower clip to the right as well, and there will not be any transition blending.\nIf you have a transition selected in the inspector you will also get a preview window at the bottom of the inspector. here you can view the transition and make adjustments to it, if that’s necessary.\nTypical Animation Transitions Okay, all of this a lot of stuff to just get some animation rocking. And this certainly could use some finger practice. So before we move on into scripting Animations, let’s play with our Homage to the Cuboid again.\nThe beauty of LateUpdate()\n"});index.add({'id':14,'href':'/docs/13_Animation/','title':"13 Animation",'content':" 13 - Animation Animation is huge topic. Animation can be about bringing characters to life or about just creating a pleasing transition between two pages in app. Animation can be about huge strides and yet shines when the most subtle feelings of an character\nPhilisophical shit about Animation\nAnimation in Unity Using Unitys Animation System can be utterly simple, but also scales very well into extremely complicated Animation of Characters and blending between Animations based states. If you are familiar with Animation systems in other software like After effects, Maya or Blender, you are probably used to just selecting an object and being able to add Keyframes. This doesn’t work in Unity.\nAnimations in Unity come with two components: An Animation Clip a.k.a the actual animation and an Animation Controller. The Animation Controller can handle multiple Animations and switch or transition between Animations.\nWhile this might seems complicated in the first place, it’s actually a fantastic system. It makes all your animations easily reusable. Once set up, you can use it over and over again on any object that has the same components applied to it.\nYou also don’t HAVE to concern yourself to much with the animation controller when starting out, because Unity can handle it’s creation for you. And as classics are always a good way to get started: Let’s create our first bouncing ball!\nTo get started just add a Sphere to the scene and zero out it’s transform. You can also create Cube as a floor to bounce around on. Next we need to open the Animation Window: “Animation \u0026mdash;\u0026gt; Animation Window”. With the Sphere selected the animation window should offer you a button to create an Animation. Animation clips are actually physically saved as individual objects on your Hard drive. You could copy them to a different project, if you wanted to. Talk about re-usability!\nIf you create Animations this way Unity will automatically create an Animator Controller as well for you and apply the Animation. So you really don’t have to care about it for now, yet you will find it applied to the Sphere.\nTo start animating, we need to add Properties we want to animate. Once you click the button you are presented with all the components that are currently applied to the sphere that actually have properties that can be animated. From the transform component go ahead an add the Position and Scale parameters using the “+” icon.\nUnity will by default create an animation that does nothing and is one second long.\nTo change the values drag the playhead to the position, where you need Keyframes and add them using rightclick. You can only change the values of keyframes that are at the position of the Playhead. If you want Unity to automatically set keyframes while editing, press the little red recording button. Because you can easily make mistakes in recordig mode, the timeline head will turn red, as well as the values in the inspector. You can also use the gizmos in the editor to animate your object.\nWhile Unity will create some default interpolation for us while adding Keyframes, it’s very likely that we want to tweak them. In the lower bar of the Animation window you can switch between the Dopesheet and the Curves view. For finer control over you animation the Curves view is an indespensible tool to create great animations.\nUnity will show you the interpolation curves it created for you and you can just go ahead and grab the Keyframes. Using the handles you can adjust you interpolation between the keyframes. If you need hard changes in your animation you need work with broken handles. to switch the handle types, just select the Keyframes you want to affect and press select the type you need using the righclick menu.\nWhile you can always go in and and preview you current animations using Animation window, you also just switch to Playmode. The way we created the animation, Unity has set this up for us as an looping Animation.\nSo here is the result and the curves for my super simple bouncing ball: Todo Bouncing ball and curves \rExpand\r↕\r\rIf you are completly new to animation and want to get into I suggest looking up “The Animators Survival Kit” by Richard Williams. “The Illusion of Life” by Frank Thomas and Ollie Johnson is another great book to look at. They first introduced the “Twelve principles of animation”. To get an overview you can also do quick search on YouTube.\r\r\r\rBecause animation is hard work, Unity has at least some shortcuts set up for us, to make our lives easier: |Shift+Comma|First Keyframe| | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | |Shift+K|Key Modified| |K|Key Selected| |Shift+Period|Last Keyframe| |Period|Next Frame| |Alt+Period|Next Keyframe| |Space|Play Animation| |Comma|Previous Frame| |Alt+Comma|Previous Keyframe|\nSo now that we know how to actually create Animations, let’s look at how they are actually set up and connected on the gameObject itself.\nIf you take a look at your sphere, you will see, that the component that’s actually applied to the sphere is an “Animator”. The Animator is responsible for handling the Animation of your object and requires and Animator Controller to work. You might think this is an unnecessary step, but it is also handling things that only become relevant in more complex scenarios, like applying Root Motion. (Try it, it’s fun.)\nThe first parameter the Animator supplies is a Controller. Right now that’s probably named “Sphere”. Or if you have renamed your Sphere before creating the Animation, it’s probably named like that. If you double-click that Controller Unity will jump to the Controller in the Project View. It should be in the same folder as the Animation Clip you created. Double Click on that and the Animator Window should pop up.\nHere you will see a left side with an entry called Base Layer as well as a Blueprint like view with three elements inside. This is a “State Machine”. It handles in Animation the current object is currently in, and if and how this object can transition to another “State”. By default you be presented with three states. “Entry”, “Any State” and a state named after your Animation Clip. The Entry State will be linked to your animation clip. This shows you that, as soon as the object becomes active the animation clip will be played. If you switch into PlayMode, you will see also see progress bar appear on the State that is currently playing.\nGo ahead and create a new animation clip, or just duplicate the one you have. You can drag an drop it in to the state machine as well. As you will it will not have any connection by default, so we need to set it up. Select either one of the Animation clips and go “RightClick \u0026mdash;\u0026gt; Make Transition”. And then click on the object you want to transition to. If you want to be able yo switch been both animations, you have to create transitions in both directions. Switch into playmode to see all of this working.\nNow depending on the animation you have set up, you might notice that your animations look sluggish. The first time i did this I got really confused, about what happens. Because this whole system is set up to also manage Characters and these states could be things like jumping, running or sitting, Unity by default applies a blending operation between the states.\nTo see this select one of the arrows a.k.a transition and check the inspector. Here you will see a transition timeline. If you move the left arrow on the playbar directly next to the right one, you will be able to move the lower clip to the right as well, and there will not be any transition blending.\nIf you have a transition selected in the inspector you will also get a preview window at the bottom of the inspector. here you can view the transition and make adjustments to it, if that’s necessary.\nTypical Animation Transitions Okay, all of this a lot of stuff to just get some animation rocking. And this certainly could use some finger practice. So before we move on into scripting Animations, let’s play with our Homage to the Cuboid again.\nThe beauty of LateUpdate()\n"});index.add({'id':15,'href':'/docs/14_Lighting/','title':"14 Lighting",'content':" 14 - Lighting For creatives light is super essential as soon as you leave the strictly graphical world. Light plays an important role in setting the scene and defining the mood. Think of the warm soft lighting during sundown at the beach, or a a dark alley only lit by a lone flickering streetlamp. The Lights alone can define the feeling we get, once we look at an image. The same scene in different lighting can tell completly different stories.\ncreate some examples here\nLight Sources Unity provides you with several different light sources to create beautiful settings. All of them can be created from the Hierachy view, or by add a “Light” component to any Gameobject. Preferably an empty one, of course.\nThe most basic light source Unity offers is the “Point Light”, which resembles your typical lightbulb in the real world. It shines light from on center point in all directions. The basic settings in Unity from them include color, intensity and range. Range might seem a bit odd, as you could expect intensity to be the driving factor in how far a light should shine, right? Actually they both decide on that, in which the Range is a hard limiter on the distance the light is contributing to the scene. We will discuss the reasoning behind this later.\nNext up is the “Spot Light”. The spot lights shines in light on a very specific spot and you can adjust the cone angle to be almost 180 degrees. It also features the ominous range value.\nThe “Directional Light” casts it rays in perfect parallel manner into the scene. It is most often use as a sunlight. And while you might argue, that the sun is a perfect example of point light, it’s distance from earth makes acceptable to simplify them to perfectly parallel in this context.\nThe last light source in the List is the “Area Light” and it tells you right on the dropdown menu that it’s “baked only”. One could argue that every light source should be an area light, but to actually properly calculate Area Lights you would have to sample Light rays from different points on the Light surface, and that’s terribly expensive to do. (But for more on that matter: see below.)\nShadows If you were curious enough to add a light into the scene already, you might have realized that all of the real-time lights (Point, Spot, Directional) do not actually cast a shadow by default. To enable shadows on a light you have to enable them on the Light component by choosing either of the two possible shadow types: Hard or Soft.\nTo keep it simple: Hard Shadows may not be very realistic, but in turn they are fast. Soft shadows are slower to calculate but look much more natural. Shadows come with a few confusing settings, and directional lights even have shadows in the overall graphics settings. You only need to concern yourself with these if you actually run into problems with your shadows.\nReal-time vs baked lighting. As in the real world lighting can be a rather technical subject as well. Maybe even more so, because the interactions of light in the real world are very, very complex and thus they are extremely resource intensive to calculate. Because of this complexity of the matter, lots of these technical details are out of the scope of this book. I will link to more advances discussions on the matter below. \rExpand\r↕\r\rRay-tracing To be able to recreate the interactions of lightrays in the environment programmers invented a technique called ray-tracing. This technique actually shoots rays of light out into the scene an calculates how they interact with a given surface. The rays then bounce further until a light ray has lost all it’s emissive power.\nThis is done several, several time until you finally get an image that is noise free.\nRecent developments in hardware have led to ray-tracing becoming available in game-engines as well, but is only available on high-end hardware. Thus we will not make use of realtime ray-tracing as of now.\n\r\r\rTo cope with these limitations in rendering power Unity offers us two essential kinds of lighting. Real-time lighting and so called “baked” lighting.\nReal-time lights are re-calculated each frame. To handle this, they take quite a few shortcuts in accuracy: Real-time light doesn’t bounce. Real-time shadows a pretty much sharp, or blurred in a kind of fake way. And while this sounds depreciative I am actually more then fascinated about what you can achieve visually using these fakes. Also these light are real-time. This means they can change color or intensity. They can move. They are really fully interactive, which is great!\n“Baked” Lighting on the other hand is created using ray-tracing (s.o.). The advantages of baked lighting are manifold. Light that bounces around a scene will create a much softer and more realistic look. You will receive proper shadowing in corners as well as soft shadows.\nBaked Lighting and Global Illumination Baking refers to actually pre-calculating how the light is bouncing around the scene and storing the information in images. These images are created and stored for each object that Unity recognizes as an “static” object. This process is done once on the machine of the creator - a.k.a. your machine - and then this high quality lighting has not be recalculated on a client machine, and thus can be pretty performant on slower machines as well.\nSo how do you choose the best approach to lighting? Well, you can have both! You can select Lights and Objects which will never change to be static and thus be included in the light baking process. All lights and objects that need to be able to move around or change color can be left un-static and will be rendered as real-time objects. As light is always calculated additive, both rendering ways work fine together on an artistic level as well. Unity even provides a third option: “Precomputed real-time global illumination”. This option will not calculate Light Maps but rather so called Light “Assets”. These Light Assets store information about how Light would travel through the scene and then interact with static objects. This means the light can change at runtime and these changes will at least affect static objects in the scene.\nLighting Settings Now that we have some idea what actually happens in the background, let’s look at the settings themselves. The most important thing, and one that’s easily forgotten about, is actually setting all the meshes you want to be “Static”. On object you can find right next to the name a little checkbox for “Static”. All lights and all objects that are supposed to be baked, need to have this checkbox enabled. This might even trigger the background baking process already. If a loading bar appears in the lower right corner and your scene textures “pop” sometimes, that’s probably the case.\nTo actually get some control on the creation of baked Lighting we need to check the Lighting Settings. You can access these via “Window \u0026mdash;\u0026gt; Rendering \u0026mdash;\u0026gt; Lighting Settings”.\nThe first tab is about the Environment. Environment meaning everything Unity renders once rays don’t hit objects anymore. By default Unity has a Skybox set up for us. And in new scenes the default Directional light is here set up as sun as well, which leads to changes in horizon color when we rotate the directional light. In our topic of baking light, this horizon will lead to shadows tinted in the horizon color, as it is sampled as an emissive light source. Yet you can also change this from skybox to color or gradient.\nAdditional resources: Light of the visual artist - Richard Yot Color and Light: A Guide for the realist painter - James Gurney\nTechnical Discussions: https://learn.unity.com/tutorial/precomputed-realtime-gi-global-illumination\n"});index.add({'id':16,'href':'/docs/15_Textures/','title':"15 Textures",'content':" 15 - Textures Textures and Shaders are a tightly intertwined concept, as textures are actually additional information the shader processes to calculate the final pixels. To provide this additional information 2D images are wrapped around an 3D object along it’s UVs. These UVs are either standards defined in primitive objects, or need to be predefined in the 3D software that created the object in the firstplace.\nOnce the textures are applied they can define a whole range of information. Simple Unlit Shader will just use the color information. “Physically Based Rendering” shaders use different textures to also affect how reflections are looking, to add faked depth detail in the object or even define areas that are supposed to be emitting light. Textures are a major factor in creating photorealism. But they are also what creates the beautiful hand drawn styles you see in some games.\nBut! Textures are a thing we pretty much only import into Unity, the creation process for the most part is handled in other software. Thus we will only concern ourselves shortly with the most important texture slots and then move on to shaders.\nTextures To use textures in Unity we first need to import them. Then create a material and apply it to an object. If you select the material in the Project View, you will be show all the possible inputs and settings has.\nImage here To every input that shows a small rectangle in front a texture can be applied. These vary based on the Shader you have selected on the top. We will discuss the standard shader.\nThe first input presented to us is “Albedo” and it defines how much diffuse light is reflected from a light source. Thus you will also hear the term “diffuse” used interchangeably with albedo. You can essentially think of it as the base color of the material.\nThe next texture we can define is “metallic” and it defines what it says: how metallic the material will appear in the rendering. Why would you want ro define that? Something is either metal or it isn’t, right? Well think of a piece of metal that has some dirt on it. The plate is metal, the dirt isn’t and thus it should not reflect like metal.\nNormal Map is next. Normal maps are super interesting. You will instantly see, that they have a weird look to them. What they do us, define the direction light is reflected per pixel. They are used to add fakes deoth detail to objects. They can also be used together with Height Maps. Which will increase the effect even further.\nOcclusion Maps define how much indirect light you objects should receive. Because Light can not be calculated accurately at run-time for such light sources, these pre-calculated maps will prevent from bringing light to areas that should not receive such strong lighting.\nIf you check the box for Emission, you can also define a texture with information for which parts of the mesh should emit light. So how and where do you get such textures? Albedo or Color for unlit materials can be easily created in any painting map. PBR textures are typically created directly inside your 3D content creation software or in specialized texture creation tools like Substance Designer. But there are also many websites that provide these textures for download. Great websites to explore are listed in the additional resources for this chapter.\nSprite Animations Now textures are mostly used as static set up once and forget about them things. But there are also a few more things we can do with them. The most important being sprite animations.\nSprite animations are typically used in 2D games and are more like a special kind of texture. You will probably know them from games like good old Super Mario. But you can use them in a 3D context as well. Yet they can’t be applied to 3D objects. To use sprite animations you first need a sprite sheet containing your basic animations states. They can look something like this: Image here You import thses just like any other image, but now you need to change their setup in the inspector. Here you can change the “Texture Type” from “Default” to “Sprite (2D and UI)”. This will change the UI shortly and now you are offered different settings, the most important being “Sprite Mode”. Set this to “Multiple”. On the right side you will find a button to open the “Sprite editor”. This will allow you to “slice” the texture into a several animation frames. To do this click the Slice button in the topbar. You can try the automatic mode for slicing the sprites or manually set a grid. The latter is useful if you know exactly how big each piece is supposed to be. Click Slice and check the project view. Here you should see a lot of separated images.\nNow we need to convert this into a working animation. To do this, you can just create a new animation clip, like we did in the chapter on animation and then select all the individual frames and drag and drop them into the animation clip timeline. Unity will then automatically create a keyframe for each frame. The order in which Unity slices such textures is from left to right and then from top to bottom.\nYou kan now just drag and drop this Sprite into the scene and Unity will automatically start playing the animation once you enter play mode. You will realize, that any sprite animation you pull in there will become it’s own Gameobject and thus can be made into a prefab. So you can reuse them in any way you find suitable. Create some code for fancy Texture animations here\nRender Textures But there are more fun features to the world of Textures: RenderTextures. Render Textures are textures that are textures that are created by actually rendering the scene with a camera. They can then be used like any other texture. You could use them to create effects like portals to other worlds. They are also useful to create somethink like streaking effects. Let’s look at both worlds.\nThe first step is to actually create a RenderTexture in the ProjectView. Next we need a camera that renders TO that RenderTexture. Create a camera and in the inspector drag and drop your texture into the Render texture slot. Now you can drag the Texture onto any Gameobject in your scene and you will see the picture recorded by that camera on it. But now both cameras render the same scene. We can adjust this using RenderLayers. All objects in Unity reside on a specific Layer. Usually this is the “Default” Layer. How appropriate. No you could have some Object in you main scene and some other object on a different Layer. To create a new one, just select the Layer Dropdown menu on any object. The last entry is for adding a new Layer. All objects you want to render exclusively in your RenderTexture camera then need to be set to this Layer. On the RenderTexture camera it self you need to adjust the “Culling Mask”. The culling Mask is by default set to everything, but if you select a sepcific later, only that layer is rendered by the camera.\nNow depending on your need you might want to adjust the cameraflags as well. If you set this to “Don’t Clear”, the RenderTexture will contain the image you rendered just the frame before. Objects that are visible in the camera will then overwrite the pixels in which they are visible. This can have some interesting effects.\nMore often you will probably use “DepthOnly”. This will result This needs more mork and use case examples\nWebcam Texture Unity also allows us to grab the video feed of an attached webcam as input. This must be handled via script.\n Pixel Sorting / Manipulation Getting a Webcam texture as Input   Textures - some paid some free: https://texturehaven.com https://textures.com https://quixel.com/megascans/library\nTexture Creation: https://www.substance3d.com/products/substance-designer\n"});index.add({'id':17,'href':'/docs/16_Shaders/','title':"16 Shaders",'content':" 16 - Shaders A shader is little piece of software, or a script, that tells the graphics card how to interpret the Lighting information an object is receiving and how to interpret that light. Unlit shaders can generate these informations for themselves.\nA very simple example would be a red sphere and a white light in the scene. If the light source is sending white light, how is the sphere ending up red? How it is determining the specular light on the sphere? How is the falloff in brightness calculated? All of this done inside the shader. And while we could probably wrap our head around this, things get immensely complicated once you talk about topics like reflection or refraction.\nLuckily Unity provides us a lot of pre-built shaders. We have been using them since chapter one. But while they can be very complex, they are also very powerful an interesting.\nBut what if you want to create your own? I will spare you the hardship of learning HLSL (High-Level Shader Language) and introduce you to one of the more recent features of Unity:\nThe Shader Graph The Shader Graph is Unitys approach to make Shader creation much more accessible for beginners and it also makes shader creation a visual process. Which is great I think, because I feel it makes it easier to stay in the more creative part of your mind.\nShader Graph is a Node graph in which you can drag and drop nodes which hold mathematical operations around to create visual outputs. Now to set up and use Shader Graph you need to run either the “High Definition Render Pipeline (HDRP)” or the “Universal Render Pipline (URP)” (previously known as Lightweight Renderpipeline). If you have set your project up using all the defaults, then that is probably not the case. The easiest way will be to just create a new Project from the Unity Hub using either Pipeline. In HDRP you will have access to some more features, but it will also not be suitable for deployment to lower end devices.\nOnce you have a new Project set up, check the Package Manager to see if you have the Shader Graph package activated. If so create a new Plane in the scene, a new material and apply it to the plane, and also create a new ShaderGraph using “RightClick \u0026mdash;\u0026gt; Shader \u0026mdash;\u0026gt; Unlit Graph” in the Project View.\nOn the material you can now select the Shader Graph you just created. Now let’s look at the actual Shader Graph. In the Project View “DoubleClick” on the ShaderGraph you created. An new Window will pop up. I suggest docking it somewhere in the interface and with your Mouse hovering over the window press “Shift + Spacebar”. This will maximize the window. The same Shortcut will bring you back to normal view.\nIn the Shader Graph you will be greeted by three windows. (If not, simply press “A”.)\nThe one in the lower right is your “Main Preview”. It will preview the end result of your Shader. You can resize it by dragging the little Grey bar in the lower right corner. You can also toggle it on and of using the “Main Preview” Button in the Topbar.\nIn the upper left you will find the Blackboard. The Blackboard holds all the parameters you want to expose to an artist in the editor.\nThe last thing you will see is a “Master Node”. This is the actual thing that controls the Output of your node. This Master Node also defines some of the main properties of your ShaderGraph. When we created the ShaderGraph, we chose an “Unlit Graph”. This means our Shader will ignore any kind of lighting information. For a start this will be easier to deal with.\nThe Master Node will accept several different Inputs. So let’s start with the most obvious one: Color.\nThere is already a Color selector provided, but one that’s just here as an absolute basic. We want to create our own Color Node. To create a node either go “RightClick \u0026mdash;\u0026gt; Create Node” or press Spacebar. To find the color node, you can either just start typing, or go “Input \u0026mdash;\u0026gt; Basic \u0026mdash;\u0026gt; Color”. Now you can connect both nodes by dragging from the color output to the color input on the master node.\nNotice the Colors on the Inputs and Outputs. They will give you information about the kind of information that is passed from a to b with the number in parentheses giving another hint.\nThe pink Color that is coming from the color node is actually a Vector4. Meaning Red, Green, Blue and Alpha. The Master Node accepts a Color of type Vector3: Red, Green and Blue. (Remember this form our Coding Section?). Unity in this case will actually try it’s best to do the conversion for you itself, and will just discard the Alpha, as the Master Node has a separate alpha input.\nBe careful though! If you expect Unity to use the Alpha Channel, as Alpha when you plug the Color node into the Alpha Input of the Master Node you will be disappointed. Unity will always dispose the last channel. Thus Red will be considered the Alpha Channel in this case. You see those Colors are important.\n\rExpand\r↕\r\rTo fix this problem you can split and and combine channels using the split and combine nodes. Take a look at this setup. The split node splits the Vector4 in to four Vector1s. Then you can combine RGB together again. Here all lines have the same color, which indicates Unity is not doing any conversion.\r\r\r\rNo that we have changed the color go back to the scene view and check out your plane. Is it colored? Probably not. A real gotcha with the Shader Graph is, you have to always save it, before any changes show up in the scene. And “Ctrl + S” won’t do the trick. On the topbar of the Shader Graph Window is a “Save Asset” button. Once you click it, the shader will be recompiled and any changes will be visible in the scene.\nNodes No let’s start playing around and leverage the power of nodes. If you open up the “Create Node” Window using “Spacebar” you will see the several different Categories Unity offers and you can have a look around for yourself. I can’t go over all of them, because there are ton!\nSo we will just create a few Graphs and along the way I’ll explain some of the nodes I find most useful.\nDe-Saturate Shader Our first shader will be super simple. We want to input a Texture and then be able to adjust it slightly using parameters.\nThis is the node setup:\nAdd Image here of desaturate Shader As I knew that I want to be able to change the texture itself aswell as it’s saturation I will create two Parameters on the blackboard. A “Texture2D” and a “Vector1”. A Vector1 is essentially a float. Once created, you can create defaults and drag them into the View, so they show up as Nodes. If you hover over them in either you the Graph view or the blackboard they will be highlighted to be easier to find in complexer Graphs.\nAs you will realize the output of the Texture 2D can’t be plugged into the Master Node directly. You will actually tell Unity to “Sample” it using a “Sample 2D Texture” node. This is necessary to define how the texture is interpreted. Now you will see you are offered either separate channels or the combined RGBA we discussed earlier.\nYou can now add the Saturation node from the Artistic category and plug in your Vector1 into the saturation input. Finally hook up the Master node and make sure to hit the “Save Asset” button.\nIn the Editor you can now setup your shader in a Material, apply it and drag and drop any image into the Texture slot. You should now be able to adjust the saturation.\nMore adjustments You might have seen that the “Artist” category features way more adjustment filters. As you might imagine you can just hook them up one after the other, but be sure to think about the order of operations, as this might have an impact on the resulting image.\nHere is an example of a shader that allows for Color Temperature and Contrast adjustments as well. Here needs to be a screenshot While creating all the parameters you should make sure to set useful names for them and their reference, as well as for their defaults. Vector1 nodes for example default to 0. Plug that into the contrast node an you will get a perfect grey, completely independent of what your texture looks like\u0026hellip; That’s not a default other artists would expect. \rExpand\r↕\r\rWhy grey? The Contrast node scales the brightness around a center value. If you scale all values that range from 0 to 1 to zero you returen that center value for all colors. That’s grey.\n\r\r\rAnimated Noise Shader Okay let’s get things moving in our next Shader. Well also finally do some coding again!\nI essentially started with one “Gradient Noise”. It creates a simple noise with values between 0 and 1. As I was aiming for a more “blob-like” structure I added a contrast node right after it and increased the contrast extremely. To make sure I was not having any values above 1 or below zero I added in a clamp node. From there split ways. The output was already perfect for the alpha, for color I added a color parameter to multiply it with.\nFor the animation to appear we need a value that can create movement. You know what we need: Time! And of course there is a “Time” node. It even has a sined and cosined time value. But time alone won’t do the trick, we need a node that can actually manipulate the noise. This is where the nodes from the UV Section come in. The first node I chose to manipulate my noise was “Tiling and offset”. It automatically creates a basic UV space and will tile and offset it if you change the corresponding values. But you could also add UV map you already have in there and manipulate that.\nThe problem with one noise is, it is just repeating and that’s very obvious. That’s why I added another noise with a “Rotation” node added to it. After multiplying both noises together the looping pattern isn’t that obvious anymore.\nThe last node I added was yet another Multiply after the time node. This allows for adjustments in the speed in the animation.\nThe last Gotcha! is the settings for Alphas in Unity. By default all Shaders created in Unity are set to “Opaque” and any alpha will just be ignored. To change this we need to go into the settings of the Master node. On the Master node find the little cogwheel and click it. Here you have some advanced settings, we are interested in the “Surface” dropdown menu. Change it from “Opaque” to “Transparent”. This should allow you to see a transparent noise in the scene. And that’s it.\nLet’s script this! Scripting this shit!\nAdditional Resources on shaders: https://thebookofshaders.com/ https://catlikecoding.com/unity/tutorials/ https://www.youtube.com/watch?time_continue=1\u0026amp;v=9WW5-0N1DsI https://www.shadertoy.com/ https://en.wikibooks.org/wiki/Cg_Programming/Unity\n"});index.add({'id':18,'href':'/docs/17_Audio/','title':"17 Audio",'content':" 17 - Audio “Audio is 50%!”. I don’t know how often I heard this sentence over the years yet. And yet it surly isn’t wrong! Audio adds a completely new layer to the works you create. And for some cases I guess you could argue “Audio is even 60% of the experience!”. While you can easily close your eyes or look away, you can’t so easily block out all the sound that’s around you.\nWrite more on the importance of Audio\nNo that we have established the importance of audio in our projects, let’s look at some of the things we need to take care of, when dealing with audio in Unity. In comparison with cinema, audio in a interactive 3D world can’t be just layed out perfectly in one Audio track. Left and Right now isn’t based on the screen you look at anymore, but based on the view-axis of the camera in 3D space. If we try to convey a realistic experience, we also need a way to increase volume as soon as we come closer, and slowly fade it away while the camera departs from the source.\nLuckily enough Unity makes the process of setting these things up very convenient. To set it up in the first place, all we need is an “Audio Listener” and an “Audio Source”. The Audio Listener component comes pre setup with every scene you create and is attached to your camera. You only really need to think about it, when you deal with multiple cameras in your scene, because only one Audio Listener can be active at any given time. It has so settings to take care of and can only be turned on and off. So that’s nice!\nTODO Image of Audio Listener on Camera The Audio Source component on the other hand is a little more complex: TODO Image of Audio Source on The first thing you will need to supply to your Audio Source is an actual AudioClip. To add an AudioClip to your project in the first place, you can just drag and drop an AudioFile into your project view. Or use “RightClick \u0026mdash;\u0026gt; Import New Asset\u0026hellip;” in the project view. Then just drag an drop it into the AudioClip on your Audio Source component. If you now go ahead an enter Play mode, you will immediatly begin to hear the AudioClip you added. This works, becuse “PlayOnAwake” by default is active. You will also find some settings that will be immediately obvious: Loop, mute, pitch and Volume. Bypassing effects should be pretty much self explanatory as well.\nThis all becomes more interesting once you push the Spatial blend slider all the way to the right. This will activate the 3D Sound settings you find below. To test this out, make sure your camera and Audio source are in the exact same space in your world. Then enter Play Mode and you grab your camera and move it around in the scene, while the scene is playing. You should hear the Audio Clip fading away with distance.\nHow harsh this falloff will be can be defined in the curve below. The predefined Logarithmic Rolloff is how sound would react in the real world. If you want a more artistic approach to your Audio, you can switch this to a Linear falloff or even create a Custom falloff.\nIf you are not yet an audio nerd it is probably a good idea, to just play around with these settings to get a feeling for what they actually do. You can even add on Audio effect components like Echo and Reverb. I will not go over these in detail, as audio and audio effects are a huge topic in themselves. But remember, that all of these effects have to be calculated at run-time. So if there are Audio Clips that i.e. always have to to be distorted, it’s better to apply such effects in an external program before even importing this into unity.\nNow that we have established how audio is handled on basic level inside Unity, let’s look at handling audio in a real-world scenario. I guess there are two kinds of audio sources we will have to deal with regularly. One is environment audio that is played from objects in your scene constantly. Think of a tree in the wind. You would want to have it play the rustling of the leaves all the time. So it makes very much sense to have the audio source directly inside your prefab and have it looping as long as your scene runs.\nAdd a tiny tree that rustles in the wind Other sounds you probably want to manage in some way. You maybe want to change the background music or play Sounds when you click on a button in a menu. Now it would be really annoying to add an Audio Source to every button in your menu. This is where Audio Manager classes come in.\nSingletons Manager classes are typically an implementation of the Singleton Pattern. The idea of a singelton is, to make sure you only have exactly one instance of the class in your scene. This instance will then handle whatever needs be handled. \rExpand\r↕\r\rSingletons can be bad\u0026hellip;\n There are reasons for why Singletons are a bad idea. And Robert Nystrom goes over them in great detail in his book “Game Programming Patterns”. But as a beginner, as I assume you are, you can feel free to ignore that. But be aware of it and once you start bigger projects be sure to read up on this!\n\r\r\rSo let’s look at the implementation of an generic Singleton inside Unity. using UnityEngine;\rpublic class Singleton : MonoBehaviour\r{\rpublic static Singleton instance;\rvoid Awake(){\rif (instance == null){\rinstance = this;\r}else{\rDestroy(gameObject);\r}\r}\rpublic void Log(){\rDebug.Log(\u0026#34;This got called.\u0026#34;);\r}\r}\nWe create a class “Singleton” and then as first step declare a variable named “instance” of type “Singleton”. Thus we store a reference to ourself. Once this object is created Awake() gets called. This most likely the moment you press play, but could be at any time during your game. Then we check if instance is already assigned. If that’s not the case, we choose this object as the instance. If an instance already exists, Destroy the current which just tried to become the instance.\nBecause our class is public and static we can access it from any other class in the scene:\nusing UnityEngine;\rpublic class Caller : MonoBehaviour\r{\r// Update is called once per frame\r void Update()\r{\rif(Input.GetKey(KeyCode.A)){\rSingleton.instance.Log();\r}\r}\r} So this is how to setup a basic singleton.\nSo how can we use this to actually manage Audio in our scene?\nusing UnityEngine;\rusing UnityEngine.Audio;\rpublic class AudioManager : MonoBehaviour\r{\rpublic static AudioManager Instance;\rpublic AudioSource Music;\rpublic AudioSource Sfx;\rvoid Awake(){\rif (Instance == null){\rInstance = this;\r}else{\rDestroy(gameObject);\r}\rMusic = this.gameObject.AddComponent\u0026lt;AudioSource\u0026gt;();\rSfx = this.gameObject.AddComponent\u0026lt;AudioSource\u0026gt;();\r}\rpublic void PlayMusic(AudioClip musicClip){\rMusic.clip = musicClip;\rMusic.Play();\rMusic.loop = true;\r}\rpublic void PlaySFX(AudioClip sfxClip){\rSfx.PlayOneShot(sfxClip);\r}\r}\r As you can see we just recreate the same pattern as with our basic Singleton. The rest of the class deals with actually playing Audio. We create an AudioSource for background music and one for sound effects we might want to play. We then create a function for each of them. The difference between the two functions is how we actually play the Audio.\nIn the PlayMusic() method we set the music clip and then use the Play() function to actually play the clip. In the PlaySFX method we use the PlayOneShot() method. The difference between the two is, that we can fire multiple sounds at the the same time when using PlayOneShot(), while we can make use of the loop feature, when having a dedicated AudioSource for an AudioClip.\nSo how do we call this? using UnityEngine;\rpublic class Caller1 : MonoBehaviour\r{\rpublic AudioClip SoundFx;\rprivate void Update(){\rif(Input.GetKeyDown(KeyCode.A)){\rAudioManager.Instance.PlaySFX(SoundFx);\r}\r}\r} This pretty much straight forward, as we just call the function on the Audio Manager. The only thing you have to note, that we store the actual Audio Clip on the caller. The manager is just responsible for playing the Audio, which Audio to play is in the responsibility of the object that is calling the Manager.\nTalk about Audio Mixers?? Rly?\nProjects - Generative with Audio playing, reacting - Audio Visualizer\n- Multiple Audio Input for better Music Visualization "});index.add({'id':19,'href':'/docs/18_Augmented/','title':"18 Augmented",'content':" Disclaimer: This chapter is written based on Unity 2019.2 and ARFoundation Package Version 2.0.2. I can only properly show the setup for Android Phones as well, as I do not have an iOS development environment.\nAugmented Reality What is Augmented Reality? Designing for Augemented Reality Augmented Reality is one of the most interesting fields in design right now. In contrast to print or webdesign many of the precieved rules are not yet written. So you can still come up with radically new ways for designing in augmented reality and grab the attention of your users. On the other hand augmented reality already advanced enough for it to have some technological base that you can rely on. Apple came up with it’s ARKit framework for more recent iPhones and Googles Android System implements it’s ARCore Library to create Augmented Reality experiences. Adding on top of that are more and more devices like Microsoft’s Hololens bring these experiences directly into your field of vision. Better yet, the folks at Unity provide a Package called “ARFoundation” which aims to integrate ARCore, ARKit and many other XR Frameworks into one. Thus we as developers only have to deal with and ARFoundation and Unity will handle the implementation differences between iOS, Android an the other devices. As you can see Augmented Reality is a great place to experiment, work and design in right now.\nSetting up AR Foundation for Android To develop AR applications in Unity you first and foremost need an ARCore compatible device. Sadly that includes only the more recent flagship and upper middleclass phones. Check the List of compatible devices here: Link to compatible device list Next you need to make sure your devices (PC and Phone)are properly configured for android development. To check what to follow the guide Unity created: https://docs.unity3d.com/Manual/android-sdksetup.html So once you are ready to start, create a new “3D” Project and open the Package Manager from Windows \u0026gt; PackageManager\n"});index.add({'id':20,'href':'/docs/19_PostProcessingStack/','title':"19 Post Processing Stack",'content':" 19 - Post Processing The last thing we will cover before we move further into bigger projects will be the Unity Post Processing Stack. The Post Processing Stack is a bunch 2D Effects you can apply to the rendered image or during the rendering process. They for the most part try to emulate characteristics of films. Like Grain, Vignette and chromatic aberration. Others try to add faked realism to images by adding motion-blur and screenspace reflections.\nWe will first look at how to get the post-processing stack setup and then shortly go over the various effects, before finally looking at some practical uses.\nSetup Since the introduction of Unity 2017.3 - and you should not be on an older version - the post processing stack is installed via the Package Manager. So Window \u0026mdash;\u0026gt;Package Manager and Look for “Post Processing” and Add the Package, if it is not already installed.\nNext you will need to add the “Post Processing Layer” component to the Camera. On the Component choose the “PostProcessing” as the Layer to render to.\nNext you will need to add an empty GameObject and add the “Post Processing Volume” Component to it. And for now also check the “Is Global” checkbox and as a Layer for the GameObject choose PostProcessing as well.\nLastly you will need to create your first “Post-processing Profile” in the Project View and then drag it into the Profile slot on the Post Processing Volume. Now you should be ready to go!\nPost Processing Effects Now let’s look at the Post Processing Effects Unity supplies us with by default. I will just go over these shortly from a mostly artistic point of view, as playing around with them is easy enough. For technical discussion of the effects and their impact on performance check out the Unity Documentation.\nAmbient Occlusion Ambient Occlusion is a fake that tries to emulate the shadowing in corners. This effect will already be naturally baked into your project if you use Global Illumination. Also it only makes sense if you have corners in your geometry, for a lot of the stuff we did it probably makes not sense to add Ambient Occlusion. For scenes like the Environment from chapter one you can play around with this and try how this affects your scene.\nScreenspace Reflections Screenspace Reflections are an effect that adds fake reflections to your objects. As actual Ray-tracing in real-time is really, really computationally expensive and also exclusive to some hardware (Q3/2019) programmers came up with ways to add this fake, which takes the rendered image and applies it as reflection again.\nAuto Exposure This effect is mostly interesting when you work with environment scenes that have drastic changes in lighting. This works like the Auto exposure on your smartphone camera. If you want full creative control over your work, this is probably not the best thing to use, as with Auto exposure on a professional camera.\nDepth of Field By default cameras in Unity draw everything perfectly crisp. But if you look at recordings from cameras in the real world, that rarely is the case! Especially in cinematic works depth of field plays an very important role in creating depth in the frame, as well as focusing the viewers attention. Proper depth of field can help your works a lot!\nBloom Bloom is an effect that you can sometimes observe in recordings from the realworld. Very bright spots of light will create some kind of halo effect. But if you look at recent games, you most definitely have seen bloom in effect. Most because it is heavily over-used. You would have to have really, really bad lenses when you have such strong blooming. Also do differences in how this effect is created in a real lens and in rendering engines bloom tends to begin to flicker really fast.\nSo what I am trying to say: Use bloom if you must, but contain yourself!\nChromatic Aberration Chromatic Aberration is aiming to recreate the prism like effect camera lenses have mostly at the outer edges of the image. This effect is typically stronger in cheap lenses or lenses that have a very wide field of view. So this is very well suited for anything that mimics surveillance cameras or something like that. In most cases I would advice using this effect very subtle.\nGrain Grain emulates the slight noise that almost every recorded video or film material has. I personally am a big fan of grain, if it is well portioned. Grain can help to break up harsh rendered edges and kinda “mush” things together, that otherwise have problems fitting together. Yet it should also be portioned in a way that it doen’t impose itself ontothe viewer.\nLens Distortion Lens Distortion is yet another effect that tries to mimic problems of the real world. This will warp the image from the center in either direction. While you should tread very lightly when using this in most cases, going crazy with the scale slider can yield interesting results I guess.\nMotion Blur Motion blur fakes the effect of the time of exposure when shooting images with real-world cameras. Classic film cameras have a rotating shutter, which is necessary to allow the camera to load the next frame. The fake in Unity uses the term “Shutter Angle” as means to set the length of the motion blur. A shutter angle of 360 would blur the full frame and would not be possible in the real world. Anything between 90 and 270 is probably useful. The Sample Count simply defines the Quality of the motion blur. More samples, more quality - worse performance.\nVignette The Vignette Effect mimics a problem with real-world camera lenses. Due to the construction of camera lenses they tend to loose some of the brightness of at the corners of the frame. This effect is typically very subtle, but digital artists have realized that this also helps to draw the viewer into the center of the frame, as we tend to look at the bright elements. The best way to check this out is probably adding the effect and pushing the “Intentsity” slider all the way to 1. Then pull it back down - and then pull at least 30% off. There is a tendency to exaggerate with this effect.\nColor Grading I kept the most exciting Post Process for the end - and this is the only tool I’ll go over in great detail. Color Grading is a very, very powerful tool and has become an absolute standard tool in any kind of video production. The fact that we have access to this in a real-time engine is fantastic. Color Grading allows is to change the colors of the whole scene to perfectly set the mood of our scene. You can affect in a very granular manner or go completely nuts with it.\nThe first thing you will have to choose is the mode. This is pretty much about performance. Choose LowDefinition Range for slower devices, like mobile.\nNext up is tone-mapping. This is very important when you render your scene in HDR. This determines how very bright and dark values are handled and faded of when preparing them for display on your typical low dynamic range screen. You can either choose one of the presets or create your own. Neutral will try to not change hue and saturation while tonemapping. ACES - well, if you don’t know what ACES is, ignore it. Leaving the technical stuff to the side let’s get on with the fun stuff! First up is White Balance. White balance will affect the Color Temperature and Tinting of your scene. This slider is a little confusing as it maps from 0 to 100 and is then affecting your scene in the direct opposite way you might expect it. Normally Color temperature is defined in degrees Kelvin and lower temperatures give warmer tones, while a higher color temperature would result in a boost of cooler colors. So while Temperature works between the orange-ish and blue-ish values, Tinting will shift between green-ish and purple-ish colors.\nExamples for warm and cold scenes\nIn the “Tone” section the first option is exposure, if you are in the High Definition Range Mode. With exposure you can affect the brightness of your image. 2 Stops is either range would be values you would not exceed in a normal scenario. If you have to, maybe rethink your lighting. The Color Filter emulates a colored filter in front of your lens. You can use this to tint your image in any way you want. While you could use this to also affect the brightness of your image, I would advice against it, as you have Exposure for that kind of operation. Thus make sure to keep the the Color you choose at max brightness in your Color Picker. TODO IMAGE OF COLOR PICKER AND EXAMPLE The Hue Shift will rotate all the colors in you image around the color wheel. This is typically a very unnatural effects and should be used with care. In cinematic Color Correction tools you can apply masks in many different ways, and with maks this effect can be used way more granular and thus way more useful. TODO Example Image or Gif Examples with shifting Colors Saturation is pretty obvious I guess. This will help you to create a super colorful or vibrant world, or just the contrary. TODO I know the drill\u0026hellip; Increasing contrast will boost the bright areas even further and darken the dark areas. Decreasting contrast will “flatten” your image. EXAMPLE The Channel mixer is a more technical effect once again. Rendered images are saved in three color channels: Red, Green and Blue. With the channel mixer you can define the contribution of each channel to one of the channels. For example you could create an Black and White image just based on the information of the Red Channel. EXAMPLES The Trackballs are use for fine tuning the the colors of your image. With the ColorPicker-like circle you can define the color which you want to boost. The slider below will let you increase or decrease the over all brightness for that range.\nThe Lift Wheel will work on the darker areas a.k.a the shadows of your image. Gamma will attack the mids and Gain will work on the highlights of your scene.\nPlaying with these can really get you some interesting results and they are a very nice tool to have available as an artist.\nThe most granular tool at your disposal are the “Grading Curves”. If you know any Photo processing software you might have seen them. What’s important to note is, that the Master Curve and Red, Green and Blue Curves are only available in the Low Definition Range Mode.\nIn high definition you are left with “Hue vs Hue”, “Hue vs Sat”, “Sat vs Sat” as well as “Lum vs Sat”.\nWith “Hue vs Hue” you can shift around colors just like the Hue Shift. But you get additional control. You could example only shift the red values into a more orange-ish tone.\n“Hue vs Sat” on the other hand will allow you to desaturate certain color ranges.\n“Lum vs Sat” will allow you to affect Saturat ion based on the brightness or luminance.\n“Sat vs Sat” may be the most odd of these effects. With this curve you can saturate or de-saturate ranges based on their current Saturation.\n"});index.add({'id':21,'href':'/docs/20_MobileAndAR/','title':"20 Mobile and a R",'content':" Disclaimer: This chapter is written based on Unity 2019.2 and ARFoundation Package Version 2.0.2. I can only properly show the setup for Android Phones as well, as I do not have an iOS development environment.\nAugmented Reality Definition Designing for Augemented Reality Augmented Reality is one of the most interesting fields in design right now. In contrast to print or webdesign many of the precieved rules are not yet written. So you can still come up with radically new ways for designing in augmented reality and grab the attention of your users. On the other hand augmented reality already advanced enough for it to have some technological base that you can rely on. Apple came up with it’s ARKit framework for more recent iPhones and Googles Android System implements it’s ARCore Library to create Augmented Reality experiences. Adding on top of that are more and more devices like Microsoft’s Hololens bring these experiences directly into your field of vision. Better yet, the folks at Unity provide a Package called “ARFoundation” which aims to integrate ARCore, ARKit and many other XR Frameworks into one. Thus we as developers only have to deal with and ARFoundation and Unity will handle the implementation differences between iOS, Android an the other devices. As you can see Augmented Reality is a great place to experiment, work and design in right now.\nSetting up AR Foundation for Android To develop AR applications in Unity you first and foremost need an ARCore compatible device. Sadly that includes only the more recent flagship and upper middleclass phones. Check the List of compatible devices here: Link to compatible device list Next you need to make sure your devices (PC and Phone)are properly configured for android development. To check what to follow the guide Unity created: https://docs.unity3d.com/Manual/android-sdksetup.html So once you are ready to start, create a new “3D” Project and open the Package Manager from Windows \u0026gt; PackageManager\n"});index.add({'id':22,'href':'/docs/21_P1_ScifiTunnel/','title':"21 P1 Scifi Tunnel",'content':"Procedural Placement of Objects\n"});index.add({'id':23,'href':'/docs/22_P2_WeatherApp/','title':"22 P2 Weather App",'content':"Getting External Data through APIs\n"});index.add({'id':24,'href':'/docs/23_P3_PianoDrivenEnvironment/','title':"23 P3 Piano Driven Environment",'content':"Embedding external Scripts and connecting Data from Hardware Devices\n"});index.add({'id':25,'href':'/docs/24_P4_OpenCV_Project/','title':"24 P4 Open C v Project",'content':"Artificial Intelligence and External Script Communication\n"});index.add({'id':26,'href':'/docs/98_AdditionalResources/','title':"98 Additional Resources",'content':" Addtional Resources You finished everything ans ask yourself: What’s next? My style of writing isn’t yours? These are rescources which are somewhat related to the topic, but can ben written for other programming languages or software. Yet they still hold - in my eyes -tremendous value. So feel free to check them out!\nBooks: - The nature of Code - Daniel Shiffman - Eloquent Javascript - Marijn Haverbeke - Graphic Design: The New Basics - Ellen Lupton, Jennifer Cole Phillips\nWebsites: Catlikecoding.com - Jasper Flick\nhttps://github.com/Microsoft/MapsSDK-Unity/wiki/Getting-Started\n"});index.add({'id':27,'href':'/docs/99_Github/','title':"99 Github",'content':" Github Let’s talk about Version Control You probably noticed, or will soon, that sometimes you have an idea on how to improve your code. You reformat your code, delete some old code here some there and all is good. The next day you look at your code an realize that it was laaate last night and everything you did, was just breaking stuff. But what did you actually change last night??\nFor Unity you have two options about taking care of this. There is the easy and very convenient way of using Unity Collaborate. Once logged in you can easily upload your projects to Unity Collaborate and restore previous states of your project directly from Unity. In the free Personal Edition of Unity you will get 2GB of free Storage and all your projects will automatically be private. While using Unity Collaborate definitely fine, reading on, will help you to feel like a real hacker. Which is nice too! Also as we move through this book we will definetly look into getting code from Sources like Github.\nSo this other option is a little bit more tech-savy but will also teach you to do this independently from Unity using Git. Unity developers themselves use this to share their code with the community and have people look at examples.\nGit is a Version Control Software that is freely available. Whenever you feel like you made a good step forward you can “commit” a.k.a. save your progress and if you ever need to go back to that state - you can! Now while Git locally is nice, git “Remotes” is what makes it really awesome! This allows you to, for one have a remote backup as well as more easily collaborate with other people. And once your project grows maybe you have a team and you can all work on the same project. There are many commercial providers for remote Git-Repositories, most offer free accounts for small projects. You could look for Mircrosofts Azure Repos, GitKraken, BitBucket by Atlassian, GitLab or, as we will do Github. Github today is also owned by Microsoft. Which one you choose is totally up to you, but I will use Github through out this book, as it is what Unity Technologies is using for their public repositories.\nSo what exactly does Git do? Git allows you to store stages of your project and go back in time. This is called a commit. You can also branch out. This means you maybe have the idea for a completly new UI for your game, but don’t want to break things. Then you can create a new “branch” and develop this new UI you or the rest of your team continue working on the rest of the project. Once you finished the new UI, you can make a “pull request”. This will ask the owner of the repository (this may, or may not be you yourself) to merge the changes to your project. Before you merge the code git will make sure both branches are still compatible to one another and then merge them together.\nAll of this can be done using the GUIs provided by your Remote Repository Provider or using the commandline. We will go the commandline way, as it is universal.\nBasic Git Usage Before we can get into commandline magic we need to install git on our computer. Check out this post by derhuerst on Github Gist, to find out how:Link\nNext go ahead and create an Account at Github.com. Once your Account is created and you again open up github.com You will see a Green button with a little Book in it saying “New”. Click it. Now enter a name for your repository or and the optional description. With a free account you will not be able to choose wether the Repository will be public or private, but you can and absolutly should add a .gitignore file. Click the “Add .gitignore” Button and search for Unity and add it. This file will make sure Git will include files that are unnecessary to track. Finally click “Create Repository”.\nNow you a you have an empty repository in the cloud. Everything else we will handle from the Commandline. Go ahead and open up a “Terminal” Window on the Mac or Commandline or Powershell if you are on Windows. There are a few short Commands you will need to learn to navigate the commandline. ls short for list, will print out all the files and folders on the directory you are in. cd short for change directory, will allow you to change the directory. If you want to go deeper one level just put the name of the folder you want to enter, or the path of serveral folders you want to go. To go up a level just do a cd .. Or type the path from the beginning like cd C:\\. Now use these commands to navigate to your Unity Project Folder.\nOnce you are there type git status. This will print out the current status of the Folder. In our case it should tell you, that it is not a repository yet. So we need to initialize it: git init will do this for us. Form now on it will try to track changes to our Folder. But this is just locally, so we still need to connect it to our Github.com Repository! git remote add origin PathYoYourGitRepo.git You can just copy and paste the path from Your browser and add the .git at the end. If this goes without failure, our Project Folder and our Online Repository are linked together, but both are in different states! So while Git will not let us push to the cloud we still can pull from it. And that’s a good thing. This way we will receive the .gitignore file Github created for us. So, do a git pull origin master Git will now download the state of the project from the Cloud for us. Now we can savely add files to our repository, because git will igonre all the files and folders defined in the .gitignore-File. Everything we did just now, is a thing, that we only need to do once for every project. You will get used to it over time, but definetly feel free to use the TL;DR at the bottom to sneek at the code when doing this for other projects.\nThe following steps you will do quite often, as they are the three Key steps to track your project. It’s adding files, commiting the changes and pushing them to the cloud. git add -- all will add all the files to our repository. From now on their history and changed will be tracked by git. git commit -m “I changed the following stuff: this is a comment You might think, the -m with comment is not important. Git will not commit without a comment! Then do a push! git push origin master This will trigger an upload Github. Now all your important files will be tracked and saved in the cloud! Commit early and often!\n###TL;DR How to setup your project with Github: * Create Repo with Unity.gitignore on the Github Website * In the Commandpromt/Terminal navigate to your Unity Project Folder * Code to execute one by one: Git init \u0026lt;br\u0026gt; Git remote add origin LinkToGithubRepo.git \u0026lt;br\u0026gt; Git pull origin master \u0026lt;br\u0026gt; Git add -A \u0026lt;br\u0026gt; Git commit -m “Comment” \u0026lt;br\u0026gt; Git push origin master \u0026lt;br\u0026gt;  "});index.add({'id':28,'href':'/posts/01_The_Editor/','title':"01 the Editor",'content':" Getting started with Unity So you managed your way through the Introduction and are still here. Awesome! The first step on your Journey to learn is to actually go and download Unity. While you could just head to unity3d.com and grab the latest and greatest Version of Unity Personal, I would suggest getting the Unity Hub. Unity Hub will help you manage your Projects as well as the Versions of Unity you have installed on your machine. As you dive deeper and deeper into Unity the day will come, where you hear of a new feature and you really want to try it. And Unity Hub is great helper to automatically manage Versions of Unity! But both ways are obviously fine!\nAs you are willing to learn to code and coding is in essence a problem solving skill, I will leave the rest of the process to you. If you struggle, from now on and for the rest of this journey the Search-Engine of your choice is your best friend!\nI will show you the process of using UnityHub to manage your Projects and Unity installations. When you Start Unity Hub it will automatically show you all your latest Projects. If you don’t have one just press the “New” Button to create One. In the next Panel you can Set the Project Name and the Location where the Project will be stored. UnityHub will create a Folder with your chosen Projectname. So no need to create that folder yourself. You will also have to choose a Template. “3D” is the default option, yet we will use the “Lightweight RP” Settings. It will help to help our tiny projects run smoothly on mobile devices and it will also get us access to the ShaderGraph. Hit create and Unity will take a while to initialize your new project and start up the Editor.\nOnce Unity opens up you should see something like this: Unitys default Layout is divided in roughly 4 parts. The Hierarchy Window is a representation of all the Objects that are currently present in your scene. It can also hold more than one Scene at a time. Using the arrows you explore elements further down in the hierarchy.\nThe “Project” Window holds all Objects that are currently inside your project. You can and should organize this using folders. Make sure to name all your files and folder because things can get messy real quick and not taking care of your Folder-Structure can end being a major source of frustration further down the line. Using rightClick you can copy, paste duplicate and even create new Objects. Info about the selected object will show up in the Inspector. (See below) The “Inspector” window shows you information on the selected object. This information mainly consists of Components. While every Object will have an “Transform” Component the rest of the List will probably differ. We will look at a lot of components over time. Just remember where to find them. In the “Scene” View you can see all the objects in your scene. This will also include some Gizmos for Lights, Effects an Lightprobes. To move around in the scene view you need to remember three shortcuts: Alt + LeftClick Drag to rotate Alt + RightClick Drag to zoom Alt + MiddleClick Drag to pan the camera Once you select and Object using LeftClick an Gizmo will appear. The default should be the “move” Gizmo. Hover over one of the Axis and LeftClick Drag to move the Object along the selected axis. There are also tools for Rotation and Scale. To switch between the three you could use the buttons on the upper left toolbar. But please, please never do so. Use the Shortcuts: W - Move E - Rotate R - Scale If you wonder how these Shortcuts come to be. Why not “R” for Rotate, eh? Because it’s convenient for heavy user, like you will become. As your thumb will always rest on “alt” for navigation purposes, you will have quick access to the main tools for the editor. Also this corresponds to the Industry-Standard Keyboard Shortcuts many users know from Digital Content Creation Packaged like Maya or Houdini.\nThere is also an alternative way to move around the viewport. If you hold down the right mouse button four squares will appear. Now you can look around by dragging the mouse and move around using the WASD keys. Try it!\nOkay. That’s what you need to now for now. Let’s move forward\nTODO Principles of Coding, Principles of Design Josef Albers at the bauhaus He did ColorStudies which look very distinct. We will recreate one using Unity\nIntroducing the Bauhaus Introducing the Bauhaus While teaching programming is rather straight forward, teaching art and design is not. In the programming sessions of this book I can teach you the syntax of the language and it will always apply. And if you do not abide by it’s rules things won’t work. (This would not be true if we were using Javascript btw.) Design and Art is different. Some would argue, that there are no rules. Pablo Picasso famously said, you need to learn the rules to break them. And then there was the Bauhaus, who actually aimed for that universal language of design as going so far as trying to fix the realtionship between color and and form. Wassily Kandinsky assigned yellow, red and blue to the forms triangle, rectangle and circle. While this seems outdated, a lot can be learned form their approach to teaching and understanding design. Throughout the first chapters we will use some of their work as reference and their ideas for rules in designing things. We will complement this by their idea of experimentation. While experimenting on our designs we will also have a good chance to get our fingers accustomed to coding.\n“Homage to the Square” in Unity With Josef Albers “Homage to the Square” paintings as a goal, let’s head back to Unity. First we should start out be tidying our workspace. Unity projects come with some thing premade and we eanto to get rid of it! So delete everything in the Projects Folder except for the Materials, Scenes, Scripts and the packages folder. Now create a new Scene. You can either press ‘CTRL + N’ to create a new scene or in the Project Window: RightClick -\u0026gt; Create -\u0026gt; Scene. No let’s create our for square. In the hierarchy RightClick -\u0026gt; 3D Object -\u0026gt; Quad. Quads by default are Squares of 1x1 Unit. \rExpand\r↕\r\rPlanes You could also use a plane. For now they are interchangeable. The core differerence is, that Quads consists of 4 Vertecies and 2 Triangles and are therefor more efficient than planes which consist many more points and triangles. For our case both are absolutley fine.\r\r\r\rNow check out the Inspector with your Quad selected in the ProjectView. The Quad comes with 4 Componenents attached to it. The first component is the ‘Transform’ component. It’s jobs is to hold information about position, rotation and scale of every object in the scene. Try playing with those values to see what happens in the viewport. You can hover your mouse over the X,Y and Z Components to get a access to a slider function. Of course you can also change those value through the interaction in the viewport we discussed in the last chapter. Next up are the Mesh Filter and Mesh Renderer. The Mesh Filter will pass the Object to the Renderer and really is nothing wen need to concern ourselves with. The Mesh Renderer contains information about how and IF the Objects is rendered in the scene. Take look at the little checkbox at it’s top. If you uncheck it, rendering of the object will be disabled. The fourth component tat is added by default is a ‘Mesh Collider’. Mesh Colliders are Unitys way of telling the object to interact with the built in Physics System. We don’t need this so we can just delete it. To get rid of a component press the little cogwheel on the upper right corner and choose remove component. The least thing Unity be default provides us with, is a shader. Shaders define how objects should look in our scene by considering their interaction with lights and so on. As we are focused on trying to create a 2D Design we actually do not need any interaction with light for now, so let’s change the shader. To change it, we need a material to chnage it to! So go into your materials Folder and do RightClick ---\u0026gt; Create ---\u0026gt; Material. With the new Material selected, check th Inspector. Under the Dropdown choose Unlit ---\u0026gt; Color. Unlit Shaders do not react to light and directly represent the color of our choosing. By Clicking the Color you can pick the Color of your choosing in the Color Picker. Ignore everything else. Check your Game view to inspect what you see. (Not the Scene View!) You should have a plane, but it’s lying on the floor. Use the Viewport tools to rotate have it face towards the camera. As you now, we will need two or three more squares to fullfill our Homage to the “Homage to the Square”. Select the Objects in the Hierarchy and press CTRL +D. Alternatively Rightclick ---\u0026gt; Duplicate will do the trick as well. To actually change the Colors of each new Quad, we need two new Materials as well. So duplicate them and assign them a new color and assign the materials to the Quads, so that each Quad has it’s own material and Color. If you go into gameview, you will still only see one plane. This is because right now all of our planes are in the exact same position in space. Also they have the exact same size. So not try to push some of them slightly to the back and scale them up and position them to finish your own personal “Hommage to the Quad”.\n"});index.add({'id':29,'href':'/docs/','title':"Docs",'content':""});index.add({'id':30,'href':'/','title':"Generative Unity",'content':" Generative Unity Hello Helloooooo\n"});index.add({'id':31,'href':'/posts/','title':"Posts",'content':""});})();